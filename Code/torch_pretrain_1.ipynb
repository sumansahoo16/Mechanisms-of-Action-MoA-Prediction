{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039814,
     "end_time": "2020-11-29T08:27:26.425541",
     "exception": false,
     "start_time": "2020-11-29T08:27:26.385727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Notebook is an Updated version of my previous kernel https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037953,
     "end_time": "2020-11-29T08:27:26.501849",
     "exception": false,
     "start_time": "2020-11-29T08:27:26.463896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# If U find my work helpful and consider forking it, please do Upvote :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:26.586725Z",
     "iopub.status.busy": "2020-11-29T08:27:26.585630Z",
     "iopub.status.idle": "2020-11-29T08:27:27.468748Z",
     "shell.execute_reply": "2020-11-29T08:27:27.467459Z"
    },
    "papermill": {
     "duration": 0.928273,
     "end_time": "2020-11-29T08:27:27.468897",
     "exception": false,
     "start_time": "2020-11-29T08:27:26.540624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:27.557056Z",
     "iopub.status.busy": "2020-11-29T08:27:27.556167Z",
     "iopub.status.idle": "2020-11-29T08:27:29.019954Z",
     "shell.execute_reply": "2020-11-29T08:27:29.018694Z"
    },
    "papermill": {
     "duration": 1.511501,
     "end_time": "2020-11-29T08:27:29.020092",
     "exception": false,
     "start_time": "2020-11-29T08:27:27.508591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss ,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import load,dump\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:29.105419Z",
     "iopub.status.busy": "2020-11-29T08:27:29.103240Z",
     "iopub.status.idle": "2020-11-29T08:27:29.106189Z",
     "shell.execute_reply": "2020-11-29T08:27:29.106786Z"
    },
    "papermill": {
     "duration": 0.047367,
     "end_time": "2020-11-29T08:27:29.106964",
     "exception": false,
     "start_time": "2020-11-29T08:27:29.059597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:29.190235Z",
     "iopub.status.busy": "2020-11-29T08:27:29.189230Z",
     "iopub.status.idle": "2020-11-29T08:27:29.197927Z",
     "shell.execute_reply": "2020-11-29T08:27:29.198907Z"
    },
    "papermill": {
     "duration": 0.053118,
     "end_time": "2020-11-29T08:27:29.199112",
     "exception": false,
     "start_time": "2020-11-29T08:27:29.145994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_scored.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:29.288981Z",
     "iopub.status.busy": "2020-11-29T08:27:29.287906Z",
     "iopub.status.idle": "2020-11-29T08:27:37.464066Z",
     "shell.execute_reply": "2020-11-29T08:27:37.463101Z"
    },
    "papermill": {
     "duration": 8.223973,
     "end_time": "2020-11-29T08:27:37.464198",
     "exception": false,
     "start_time": "2020-11-29T08:27:29.240225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "df = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:37.550634Z",
     "iopub.status.busy": "2020-11-29T08:27:37.549174Z",
     "iopub.status.idle": "2020-11-29T08:27:37.624594Z",
     "shell.execute_reply": "2020-11-29T08:27:37.623977Z"
    },
    "papermill": {
     "duration": 0.120448,
     "end_time": "2020-11-29T08:27:37.624730",
     "exception": false,
     "start_time": "2020-11-29T08:27:37.504282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features2=train_features.copy()\n",
    "test_features2=test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:37.712887Z",
     "iopub.status.busy": "2020-11-29T08:27:37.711927Z",
     "iopub.status.idle": "2020-11-29T08:27:37.715919Z",
     "shell.execute_reply": "2020-11-29T08:27:37.715329Z"
    },
    "papermill": {
     "duration": 0.050314,
     "end_time": "2020-11-29T08:27:37.716044",
     "exception": false,
     "start_time": "2020-11-29T08:27:37.665730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:37.810838Z",
     "iopub.status.busy": "2020-11-29T08:27:37.809500Z",
     "iopub.status.idle": "2020-11-29T08:27:49.166175Z",
     "shell.execute_reply": "2020-11-29T08:27:49.167082Z"
    },
    "papermill": {
     "duration": 11.410611,
     "end_time": "2020-11-29T08:27:49.167350",
     "exception": false,
     "start_time": "2020-11-29T08:27:37.756739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:49.268768Z",
     "iopub.status.busy": "2020-11-29T08:27:49.267855Z",
     "iopub.status.idle": "2020-11-29T08:27:49.657564Z",
     "shell.execute_reply": "2020-11-29T08:27:49.656645Z"
    },
    "papermill": {
     "duration": 0.438236,
     "end_time": "2020-11-29T08:27:49.657696",
     "exception": false,
     "start_time": "2020-11-29T08:27:49.219460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:27:49.755415Z",
     "iopub.status.busy": "2020-11-29T08:27:49.753880Z",
     "iopub.status.idle": "2020-11-29T08:28:03.240759Z",
     "shell.execute_reply": "2020-11-29T08:28:03.239945Z"
    },
    "papermill": {
     "duration": 13.542407,
     "end_time": "2020-11-29T08:28:03.240882",
     "exception": false,
     "start_time": "2020-11-29T08:27:49.698475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 600  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "gpca= (pca_g.fit(data[GENES]))\n",
    "train2= (gpca.transform(train_features[GENES]))\n",
    "test2 = (gpca.transform(test_features[GENES]))\n",
    "\n",
    "train_gpca = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test_gpca = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train_gpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_gpca), axis=1)\n",
    "\n",
    "dump(gpca, open('gpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:03.336966Z",
     "iopub.status.busy": "2020-11-29T08:28:03.335473Z",
     "iopub.status.idle": "2020-11-29T08:28:04.352046Z",
     "shell.execute_reply": "2020-11-29T08:28:04.352826Z"
    },
    "papermill": {
     "duration": 1.071012,
     "end_time": "2020-11-29T08:28:04.353041",
     "exception": false,
     "start_time": "2020-11-29T08:28:03.282029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "pca_c = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "cpca= (pca_c.fit(data[CELLS]))\n",
    "train2= (cpca.transform(train_features[CELLS]))\n",
    "test2 = (cpca.transform(test_features[CELLS]))\n",
    "\n",
    "train_cpca = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test_cpca = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train_cpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_cpca), axis=1)\n",
    "\n",
    "dump(cpca, open('cpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:04.472909Z",
     "iopub.status.busy": "2020-11-29T08:28:04.472090Z",
     "iopub.status.idle": "2020-11-29T08:28:05.250757Z",
     "shell.execute_reply": "2020-11-29T08:28:05.250106Z"
    },
    "papermill": {
     "duration": 0.830549,
     "end_time": "2020-11-29T08:28:05.250897",
     "exception": false,
     "start_time": "2020-11-29T08:28:04.420348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "mask = (train_features[c_n].var() >= 0.85).values\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:05.347054Z",
     "iopub.status.busy": "2020-11-29T08:28:05.346169Z",
     "iopub.status.idle": "2020-11-29T08:28:55.326422Z",
     "shell.execute_reply": "2020-11-29T08:28:55.325292Z"
    },
    "papermill": {
     "duration": 50.034344,
     "end_time": "2020-11-29T08:28:55.326570",
     "exception": false,
     "start_time": "2020-11-29T08:28:05.292226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 22, SEED = 42):\n",
    "    \n",
    "    features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_genes(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:55.425353Z",
     "iopub.status.busy": "2020-11-29T08:28:55.423762Z",
     "iopub.status.idle": "2020-11-29T08:28:57.418402Z",
     "shell.execute_reply": "2020-11-29T08:28:57.417789Z"
    },
    "papermill": {
     "duration": 2.050738,
     "end_time": "2020-11-29T08:28:57.418535",
     "exception": false,
     "start_time": "2020-11-29T08:28:55.367797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 4, SEED = 42):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_cells(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:57.512745Z",
     "iopub.status.busy": "2020-11-29T08:28:57.511226Z",
     "iopub.status.idle": "2020-11-29T08:28:57.610361Z",
     "shell.execute_reply": "2020-11-29T08:28:57.610914Z"
    },
    "papermill": {
     "duration": 0.150478,
     "end_time": "2020-11-29T08:28:57.611080",
     "exception": false,
     "start_time": "2020-11-29T08:28:57.460602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "test_pca=pd.concat((test_gpca,test_cpca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:28:57.706002Z",
     "iopub.status.busy": "2020-11-29T08:28:57.704467Z",
     "iopub.status.idle": "2020-11-29T08:29:14.893654Z",
     "shell.execute_reply": "2020-11-29T08:29:14.893013Z"
    },
    "papermill": {
     "duration": 17.241476,
     "end_time": "2020-11-29T08:29:14.893785",
     "exception": false,
     "start_time": "2020-11-29T08:28:57.652309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_pca(train, test,n_clusters=5,SEED = 42):\n",
    "        data=pd.concat([train,test],axis=0)\n",
    "        kmeans_pca = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_pca, open('kmeans_pca.pkl', 'wb'))\n",
    "        train[f'clusters_pca'] = kmeans_pca.predict(train.values)\n",
    "        test[f'clusters_pca'] = kmeans_pca.predict(test.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "        return train, test\n",
    "train_cluster_pca ,test_cluster_pca = fe_cluster_pca(train_pca,test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:14.986095Z",
     "iopub.status.busy": "2020-11-29T08:29:14.985046Z",
     "iopub.status.idle": "2020-11-29T08:29:14.988022Z",
     "shell.execute_reply": "2020-11-29T08:29:14.988555Z"
    },
    "papermill": {
     "duration": 0.052537,
     "end_time": "2020-11-29T08:29:14.988710",
     "exception": false,
     "start_time": "2020-11-29T08:29:14.936173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cluster_pca = train_cluster_pca.iloc[:,650:]\n",
    "test_cluster_pca = test_cluster_pca.iloc[:,650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:15.078968Z",
     "iopub.status.busy": "2020-11-29T08:29:15.078157Z",
     "iopub.status.idle": "2020-11-29T08:29:15.084693Z",
     "shell.execute_reply": "2020-11-29T08:29:15.084040Z"
    },
    "papermill": {
     "duration": 0.054247,
     "end_time": "2020-11-29T08:29:15.084851",
     "exception": false,
     "start_time": "2020-11-29T08:29:15.030604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_cluster=train_features2.iloc[:,876:]\n",
    "test_features_cluster=test_features2.iloc[:,876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:15.177231Z",
     "iopub.status.busy": "2020-11-29T08:29:15.176373Z",
     "iopub.status.idle": "2020-11-29T08:29:15.180657Z",
     "shell.execute_reply": "2020-11-29T08:29:15.180056Z"
    },
    "papermill": {
     "duration": 0.053804,
     "end_time": "2020-11-29T08:29:15.180774",
     "exception": false,
     "start_time": "2020-11-29T08:29:15.126970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:15.296146Z",
     "iopub.status.busy": "2020-11-29T08:29:15.285761Z",
     "iopub.status.idle": "2020-11-29T08:29:21.309543Z",
     "shell.execute_reply": "2020-11-29T08:29:21.310932Z"
    },
    "papermill": {
     "duration": 6.087367,
     "end_time": "2020-11-29T08:29:21.311160",
     "exception": false,
     "start_time": "2020-11-29T08:29:15.223793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-26'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        df['c26_c38'] = df['c-26'] * df['c-38']\n",
    "        df['c90_c13'] = df['c-90'] * df['c-13']\n",
    "        df['c85_c31'] = df['c-85'] * df['c-31']\n",
    "        df['c63_c42'] = df['c-63'] * df['c-42']\n",
    "        df['c94_c11'] = df['c-94'] * df['c-11']\n",
    "        df['c94_c60'] = df['c-94'] * df['c-60']\n",
    "        df['c55_c42'] = df['c-55'] * df['c-42']\n",
    "        df['g37_c50'] = df['g-37'] * df['g-50']\n",
    "        \n",
    "        \n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "                \n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2        \n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features2,test_features2=fe_stats(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:21.474577Z",
     "iopub.status.busy": "2020-11-29T08:29:21.473650Z",
     "iopub.status.idle": "2020-11-29T08:29:21.477952Z",
     "shell.execute_reply": "2020-11-29T08:29:21.477381Z"
    },
    "papermill": {
     "duration": 0.094379,
     "end_time": "2020-11-29T08:29:21.478079",
     "exception": false,
     "start_time": "2020-11-29T08:29:21.383700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_stats=train_features2.iloc[:,902:]\n",
    "test_features_stats=test_features2.iloc[:,902:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:21.571952Z",
     "iopub.status.busy": "2020-11-29T08:29:21.570777Z",
     "iopub.status.idle": "2020-11-29T08:29:21.704572Z",
     "shell.execute_reply": "2020-11-29T08:29:21.703912Z"
    },
    "papermill": {
     "duration": 0.183651,
     "end_time": "2020-11-29T08:29:21.704695",
     "exception": false,
     "start_time": "2020-11-29T08:29:21.521044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat((train_features, train_features_cluster,train_cluster_pca,train_features_stats), axis=1)\n",
    "test_features = pd.concat((test_features, test_features_cluster,test_cluster_pca,test_features_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:21.801016Z",
     "iopub.status.busy": "2020-11-29T08:29:21.799945Z",
     "iopub.status.idle": "2020-11-29T08:29:21.948096Z",
     "shell.execute_reply": "2020-11-29T08:29:21.948673Z"
    },
    "papermill": {
     "duration": 0.201555,
     "end_time": "2020-11-29T08:29:21.948859",
     "exception": false,
     "start_time": "2020-11-29T08:29:21.747304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 targets without ANY mechanism of action in the nonscored dataset\n"
     ]
    }
   ],
   "source": [
    "#Extract unique elements per column\n",
    "cols2 = train_targets_nonscored.columns.to_list() # specify the columns whose unique values you want here\n",
    "uniques2 = {col: train_targets_nonscored[col].nunique() for col in cols2}\n",
    "uniques2=pd.DataFrame(uniques2, index=[0]).T\n",
    "uniques2=uniques2.rename(columns={0:'count'})\n",
    "uniques2= uniques2.drop('sig_id', axis=0)\n",
    "print(f\"{len(uniques2[uniques2['count']==1])} targets without ANY mechanism of action in the nonscored dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:22.066440Z",
     "iopub.status.busy": "2020-11-29T08:29:22.064051Z",
     "iopub.status.idle": "2020-11-29T08:29:22.069604Z",
     "shell.execute_reply": "2020-11-29T08:29:22.069044Z"
    },
    "papermill": {
     "duration": 0.077302,
     "end_time": "2020-11-29T08:29:22.069725",
     "exception": false,
     "start_time": "2020-11-29T08:29:21.992423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonmoacols=uniques2[uniques2['count']==1].index\n",
    "train_targets_nonscored_columns = [col for col in list(train_targets_nonscored.columns) if col not in nonmoacols]\n",
    "train_targets_nonscored=train_targets_nonscored[train_targets_nonscored_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:22.167202Z",
     "iopub.status.busy": "2020-11-29T08:29:22.165781Z",
     "iopub.status.idle": "2020-11-29T08:29:22.835127Z",
     "shell.execute_reply": "2020-11-29T08:29:22.834070Z"
    },
    "papermill": {
     "duration": 0.721151,
     "end_time": "2020-11-29T08:29:22.835263",
     "exception": false,
     "start_time": "2020-11-29T08:29:22.114112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_nonscored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.011657Z",
     "iopub.status.busy": "2020-11-29T08:29:23.010520Z",
     "iopub.status.idle": "2020-11-29T08:29:23.030307Z",
     "shell.execute_reply": "2020-11-29T08:29:23.029644Z"
    },
    "papermill": {
     "duration": 0.151392,
     "end_time": "2020-11-29T08:29:23.030499",
     "exception": false,
     "start_time": "2020-11-29T08:29:22.879107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.146337Z",
     "iopub.status.busy": "2020-11-29T08:29:23.125021Z",
     "iopub.status.idle": "2020-11-29T08:29:23.149133Z",
     "shell.execute_reply": "2020-11-29T08:29:23.148507Z"
    },
    "papermill": {
     "duration": 0.074467,
     "end_time": "2020-11-29T08:29:23.149254",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.074787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.245941Z",
     "iopub.status.busy": "2020-11-29T08:29:23.244824Z",
     "iopub.status.idle": "2020-11-29T08:29:23.454037Z",
     "shell.execute_reply": "2020-11-29T08:29:23.454575Z"
    },
    "papermill": {
     "duration": 0.261433,
     "end_time": "2020-11-29T08:29:23.454734",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.193301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['cp_time','cp_dose'])\n",
    "test_ = pd.get_dummies(test, columns=['cp_time','cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.557995Z",
     "iopub.status.busy": "2020-11-29T08:29:23.552159Z",
     "iopub.status.idle": "2020-11-29T08:29:23.560764Z",
     "shell.execute_reply": "2020-11-29T08:29:23.560200Z"
    },
    "papermill": {
     "duration": 0.061684,
     "end_time": "2020-11-29T08:29:23.560889",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.499205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.655470Z",
     "iopub.status.busy": "2020-11-29T08:29:23.654228Z",
     "iopub.status.idle": "2020-11-29T08:29:23.659342Z",
     "shell.execute_reply": "2020-11-29T08:29:23.659858Z"
    },
    "papermill": {
     "duration": 0.054744,
     "end_time": "2020-11-29T08:29:23.660003",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.605259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.764572Z",
     "iopub.status.busy": "2020-11-29T08:29:23.763499Z",
     "iopub.status.idle": "2020-11-29T08:29:23.767047Z",
     "shell.execute_reply": "2020-11-29T08:29:23.766466Z"
    },
    "papermill": {
     "duration": 0.061404,
     "end_time": "2020-11-29T08:29:23.767176",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.705772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.876410Z",
     "iopub.status.busy": "2020-11-29T08:29:23.875395Z",
     "iopub.status.idle": "2020-11-29T08:29:23.878875Z",
     "shell.execute_reply": "2020-11-29T08:29:23.878291Z"
    },
    "papermill": {
     "duration": 0.066542,
     "end_time": "2020-11-29T08:29:23.878993",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.812451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:23.983435Z",
     "iopub.status.busy": "2020-11-29T08:29:23.982334Z",
     "iopub.status.idle": "2020-11-29T08:29:23.985107Z",
     "shell.execute_reply": "2020-11-29T08:29:23.985653Z"
    },
    "papermill": {
     "duration": 0.06199,
     "end_time": "2020-11-29T08:29:23.985807",
     "exception": false,
     "start_time": "2020-11-29T08:29:23.923817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:24.092130Z",
     "iopub.status.busy": "2020-11-29T08:29:24.091227Z",
     "iopub.status.idle": "2020-11-29T08:29:24.095783Z",
     "shell.execute_reply": "2020-11-29T08:29:24.095144Z"
    },
    "papermill": {
     "duration": 0.064938,
     "end_time": "2020-11-29T08:29:24.095897",
     "exception": false,
     "start_time": "2020-11-29T08:29:24.030959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x), 1e-3)\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:24.194732Z",
     "iopub.status.busy": "2020-11-29T08:29:24.194003Z",
     "iopub.status.idle": "2020-11-29T08:29:24.198697Z",
     "shell.execute_reply": "2020-11-29T08:29:24.199257Z"
    },
    "papermill": {
     "duration": 0.05798,
     "end_time": "2020-11-29T08:29:24.199444",
     "exception": false,
     "start_time": "2020-11-29T08:29:24.141464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:24.322401Z",
     "iopub.status.busy": "2020-11-29T08:29:24.317190Z",
     "iopub.status.idle": "2020-11-29T08:29:24.325848Z",
     "shell.execute_reply": "2020-11-29T08:29:24.325082Z"
    },
    "papermill": {
     "duration": 0.080033,
     "end_time": "2020-11-29T08:29:24.325974",
     "exception": false,
     "start_time": "2020-11-29T08:29:24.245941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7,random_state=seed)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_nonscored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_nonscored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:24.426633Z",
     "iopub.status.busy": "2020-11-29T08:29:24.425587Z",
     "iopub.status.idle": "2020-11-29T08:29:24.428298Z",
     "shell.execute_reply": "2020-11-29T08:29:24.428887Z"
    },
    "papermill": {
     "duration": 0.057235,
     "end_time": "2020-11-29T08:29:24.429025",
     "exception": false,
     "start_time": "2020-11-29T08:29:24.371790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:29:24.531691Z",
     "iopub.status.busy": "2020-11-29T08:29:24.530157Z",
     "iopub.status.idle": "2020-11-29T08:55:57.915743Z",
     "shell.execute_reply": "2020-11-29T08:55:57.916296Z"
    },
    "papermill": {
     "duration": 1593.441666,
     "end_time": "2020-11-29T08:55:57.916516",
     "exception": false,
     "start_time": "2020-11-29T08:29:24.474850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.5882393943296896\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08300556414402448\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.016584956502491557\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.005982428538398101\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.00924598506173572\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005973209985173666\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.00920553004520165\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0059161509673755905\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.009035062636374621\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005468068966785302\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.008978247315295645\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0064336918652630765\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.008936723675327125\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005438302213755937\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.008927368005183903\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005512953306046816\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.008915448284431084\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005395108260787451\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.008913752824269436\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005465166464161415\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.008917119593132992\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005525483606526485\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.008919303783693829\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005526968063070224\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.008930335161150308\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.00545779590566571\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.00890788812869908\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005476635809128101\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.008909459729251024\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005464819833063162\n",
      "SEED: 0, FOLD: 0, EPOCH: 15, train_loss: 0.008881179987125704\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005487806342828732\n",
      "SEED: 0, FOLD: 0, EPOCH: 16, train_loss: 0.008855301937138712\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 16, valid_loss: 0.0054443152621388435\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.5867653275663788\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08119699817437392\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.016332466142705164\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006131096528126643\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.009321356557208943\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005884894993729317\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.009286606545887283\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.006358248145821003\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.009060588401012324\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.00557072783032289\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.008969151131758417\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005525882534969311\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.008937780147519064\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005413645878434181\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.008927516651818075\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005789801764946718\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.00892163232925373\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005402724186961467\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.008926883188856614\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005386411821326384\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.008917792108715386\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005531067458482889\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.008905784327637506\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0055613483732136395\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.008918671837277911\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005503201678108711\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.00891106208232609\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005509227335166473\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.008889387474974265\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.00547766825184226\n",
      "SEED: 0, FOLD: 1, EPOCH: 15, train_loss: 0.008861895254183863\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005416239361063792\n",
      "SEED: 0, FOLD: 1, EPOCH: 16, train_loss: 0.008855044476788592\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005397748202085495\n",
      "SEED: 0, FOLD: 1, EPOCH: 17, train_loss: 0.008837449011971822\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 17, valid_loss: 0.005384758867036838\n",
      "SEED: 0, FOLD: 1, EPOCH: 18, train_loss: 0.008794850877460998\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 18, valid_loss: 0.005374376805355916\n",
      "SEED: 0, FOLD: 1, EPOCH: 19, train_loss: 0.00875298843114964\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 19, valid_loss: 0.005339177432828224\n",
      "SEED: 0, FOLD: 1, EPOCH: 20, train_loss: 0.008704133489093668\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 20, valid_loss: 0.005318679381161928\n",
      "SEED: 0, FOLD: 1, EPOCH: 21, train_loss: 0.008648766204714775\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 21, valid_loss: 0.005265224832468308\n",
      "SEED: 0, FOLD: 1, EPOCH: 22, train_loss: 0.00860885571612901\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 22, valid_loss: 0.005282417083015809\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.5867854721240096\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07107200301610507\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.016712647711707128\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005947329963629062\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.009298691614153417\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005572246423420997\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.009156058869651845\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005716259555461315\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.009192440268659108\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005635761118565614\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.00895683717209141\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005524166197014542\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.008936940811926851\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0054357221994835595\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.008924354918653498\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005559607982062376\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.008922631688718055\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005427896618269957\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.008919889333884459\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0055306434559707456\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.008914574061998644\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.00544991297647357\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.008896160537276316\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005451228093499174\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.008904272671537223\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005450571278253427\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.008892444830790564\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005576414378503194\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.008887492145436842\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005520207986522179\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.008867628255707992\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005540167590459952\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.5873555761535425\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07971943456393021\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.016636319659851694\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061167621841797465\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.009272712408690839\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.00595416110725357\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.00920859823708196\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005852065729693725\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.009210260295485323\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.00556502201092931\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.008966677180315191\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.006252843814973648\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.008937395184074302\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005906920306957685\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.008922566697504875\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005685062756618628\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.0089223313246023\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005749702525253479\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.008912886719445925\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005788599212582295\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.00891861303180859\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005707990378141403\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.008907967007945519\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005705576569128495\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.008903565741068608\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005629103129299788\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.008878497343913123\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005668844275463086\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.008875488530139666\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.00560013591670073\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.5894761420786381\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08443128145658053\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.016616376104286394\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006204285945456762\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.009273922788230953\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.006000207522167609\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.010249426871588503\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005698585488761847\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.009184525058780974\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005651675845281436\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.009054136487680513\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005817559332801745\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.009023749099641636\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005755112864650213\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.008977645869694045\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005594222484013209\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.008934575787468537\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005600910741262711\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.008919090687020405\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.0056822337210178375\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.008906355001837821\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005591351252335768\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.00888077328862572\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005552311356251056\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.008873691385913943\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.00566705552717814\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.008869830481204632\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.00558343819844035\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.008840803736569109\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005649372541274016\n",
      "SEED: 0, FOLD: 4, EPOCH: 15, train_loss: 0.00881948834914412\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 15, valid_loss: 0.0056310494860204365\n",
      "SEED: 0, FOLD: 4, EPOCH: 16, train_loss: 0.00878877384663635\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 16, valid_loss: 0.0055775402400356075\n",
      "SEED: 0, FOLD: 4, EPOCH: 17, train_loss: 0.008762777191460938\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 17, valid_loss: 0.0056470837085866015\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.5899181918719331\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08330265432596207\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.01705764830615875\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006156856373239022\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.009315618225750891\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.00558402192277404\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.00944123084883432\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005558721792812531\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.00916407527905461\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.018398076725693848\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.009127051166787341\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005543743152744495\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.008992793686637605\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.0054649876502270885\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.008960161320361737\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005535444101461997\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.008946448539358538\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005639195442199707\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.008934594980264837\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005662119051871391\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.008933753530318672\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005597446257105241\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.00891553480303972\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005527438882451791\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.008893234774822721\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005469136369916109\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.008888826894296988\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.0056160861053145845\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.008883529361589131\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.0055128661915659904\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.008856986082989621\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.00548641372901889\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.5896100735140813\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07890549359413293\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.016805457253311132\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006097730535727281\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.009307856671512127\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005714727314905479\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.00931983147873669\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.0054338851657051305\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.009060919448431279\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005591896899904196\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.00894851895124727\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005461330167376078\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.008906238850810239\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005739419112125268\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.008919222550970074\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005428721519330373\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.00891090349319416\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005452197152548111\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.008890695913971678\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005428562728831401\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.008898491983780184\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005474774847523524\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.008910310731546299\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005498835243857824\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.008891208814708767\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005588741793941993\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.00887228232632215\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.00546756898984313\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.008877892525413551\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.0054919124724200135\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.0088641432214629\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.0055128030407314114\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.5873665890178165\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07767212448211816\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.016564172654840593\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006391159008042171\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.009314896626951726\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0058685911890979\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.009184462918169998\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005954914153195345\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.009025523778856607\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005658466333093552\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.008923583462632992\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0056588863595747035\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.008918447728344315\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.00559419529655805\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.008918504935462732\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00549882915444099\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.00890500787519724\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.00568863613387713\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.00891082367633243\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005514238423739488\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.008898272028041852\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005474568846134039\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.00890014587423286\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0055327709907522565\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.008901334594230394\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005572358146309853\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.008906062207864347\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005583727624840462\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.008866506817473753\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005556674889073922\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: nan\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: nan\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: nan\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: nan\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.5876638972880067\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07702444894955708\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.016746249679173972\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.0063093461884328956\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.009303330028479969\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005857234032681355\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.009236555433253179\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.0056920197720711045\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.009100863722631254\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005586344497994735\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.008954775192447612\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005610909456243882\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.008941243522221575\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005591448396444321\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.008912269334384316\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005681950992976244\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.008890841124780677\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00556927199403827\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.008900514980022972\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.00551859622534651\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.008894037348344116\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005688345919434841\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.008878638237916134\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0055628579396467944\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.008900963965602018\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005567393767145963\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.0088869465414334\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005571884676240957\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.008880876791285904\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005589015208757841\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.008855362630424064\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005573909550618667\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.008826283498893719\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005522585688875272\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.5868085678163413\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.09316875269779792\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.016584333560958103\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006147925921071034\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.00926604144577239\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005703868953367839\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.010037553924563769\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005589554981830029\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.009122697800095822\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005434948521164747\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.009027050468265204\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.00552382986419476\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.008984901036161024\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005563633158229864\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.008960799861548317\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.00547546621125478\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.008925787236138776\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005552514671133115\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.008934316112080941\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005432664022709315\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.00892166284894621\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005520282098307059\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.008910182605472368\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005523697902949957\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.008908793890244654\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005442672230016727\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.008897416520158987\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005447247137243931\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.008859007537515985\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.0054839181427199105\n",
      "SEED: 1, FOLD: 2, EPOCH: 15, train_loss: 0.008851356080708068\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005463497892308693\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.5865817684176806\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0737109614106325\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.01662263008640022\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006232688275094216\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.009314281349951352\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005816678803127546\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.009125878732349421\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005803785286843777\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.009063590984992884\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005555727698195439\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.008938178495579475\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005727543567235653\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.008909962158901868\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005613361771863241\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.008908239929508921\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0055698143103374885\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.00890219779181722\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005627017611494431\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.008903635470700022\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005544268060475588\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.008887747422213087\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005614820652856276\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.008902417382577786\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0055501006113795135\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.008906097667342102\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005542691223896467\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.008893525743907367\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005646970337973191\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.00886368251883903\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005588468307485947\n",
      "SEED: 1, FOLD: 3, EPOCH: 15, train_loss: 0.008864168813955542\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005535544254458868\n",
      "SEED: 1, FOLD: 3, EPOCH: 16, train_loss: 0.008842968721748204\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 16, valid_loss: 0.0056197014279090445\n",
      "SEED: 1, FOLD: 3, EPOCH: 17, train_loss: 0.008808890986885573\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 17, valid_loss: 0.00548106636135624\n",
      "SEED: 1, FOLD: 3, EPOCH: 18, train_loss: 0.008785280096973921\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 18, valid_loss: 0.005465041595296218\n",
      "SEED: 1, FOLD: 3, EPOCH: 19, train_loss: 0.008742242113913636\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 19, valid_loss: 0.005481446985728466\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.5884683256012362\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.07751579181506084\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.016742706739318533\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006171124557463022\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.009297144668478821\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005724374133233841\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.009126661244679141\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0057178299086025125\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.009035845123533462\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.006046613141034658\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.008937158911312753\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.0054303890882203215\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.008915507675123375\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005679594352841377\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.008899409588224985\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005649393496031945\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.008912183835196335\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005335890222340822\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.008907514240441693\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005459433027471487\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.008922703784412227\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005462706089019775\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.008923083990560594\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.0055432852644186755\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.008920408055387638\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0055229229351075795\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.008911316742415767\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.00548791097333798\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.008891603531869682\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005505730612919881\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.008876868674682604\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005523166475960841\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.5875005817695244\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07301251532939765\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.016573697064273262\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006249161401333718\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.009298853676866841\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005976718957894123\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.00932088162045221\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.0055411760695278645\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.009128549803249739\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005561173535310305\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.008945814308685225\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005811142162061655\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.008954897875318656\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005477658616235623\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.008933179546147585\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005418257931104073\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.008916138042066549\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005517934556477345\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.008917668651839768\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.00553397021184747\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.008908779335183066\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005696727500225489\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.008907844960639203\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005525541850007498\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.008893981343135238\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005551349407491775\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: nan\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: nan\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: nan\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: nan\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: nan\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: nan\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.5889675889063526\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08372993423388554\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.01669830533147261\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006377774469840985\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.009368548534709859\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.0059912026000137515\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.009251155361935898\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.00689111384921349\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.009087453382341442\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0054639703952349145\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.008968690938844875\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.006608434343853822\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.008968931282996325\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.0056976438499987125\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.008919662430983138\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.0055825869337870525\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.008911897963214968\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005435324094903011\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.008908703306538833\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005492218089504884\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.008899704672748575\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005474305496766017\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.008906576386023615\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005555690266191959\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.008906936946299833\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.00553811789275362\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.008889050896254342\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005547808339962592\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.00889158622688941\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005526124535558315\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.5883672059186407\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08193001666894326\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.016789644906246983\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006113104414767944\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.009270163064168111\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005746965439846883\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.009171841640931528\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.009204025666874189\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.00910889113170875\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005622300283553509\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.00897837634752127\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0056486091433236236\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.008910744186692141\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.00565918914687175\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.00891041093682115\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005507307342038705\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.008898182885368934\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.0056256626446086625\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.008893362976409294\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005530867188309248\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.008891950789335612\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005529123716629469\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.008890420632638238\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005591057491703675\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.008893373963498586\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005636525412018483\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.008878924179117422\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005681079633247394\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.008868539189869488\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005591792699236136\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.5869887552752688\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08139674537456952\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.016549265289024728\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006084403739525721\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.009333702874042699\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.00568284302090223\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.009182681908478608\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005593766529972737\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.010270226205623633\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005461914464831352\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.009094178475238182\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005581473609289298\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.009029473788482515\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005821179634389969\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.009006249303048526\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005644074462067623\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.00898771286262451\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005647896000972161\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.00897662782085103\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005576668163904777\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.008954141886804151\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005563984625041485\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.00893171426110171\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005591803158705051\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.008947027570291146\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.0055775773854782945\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.008937386002995679\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005499638796139222\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.008903521754955119\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.0055571479651217275\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.5877917127029316\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08028808408058606\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.016749747449884545\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006156187325429458\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.00924664650213074\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005849269362023244\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.009211191983037704\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005809896088276918\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.009084733744227403\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005937384369854744\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.008963859212156889\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005664937019061584\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.00890845198788353\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005670542363077402\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.00890319380984717\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005644495169130655\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.008898105950573006\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005811611656099558\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.008898731044216736\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005763137104133001\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.008879344759357942\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.00556799192697956\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.008884463610278594\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005642531511302178\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.008875265906288012\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005575710406097082\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.008862778122813718\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005631398337964828\n",
      "SEED: 2, FOLD: 2, EPOCH: 14, train_loss: 0.008858704857679235\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005620089467041767\n",
      "SEED: 2, FOLD: 2, EPOCH: 15, train_loss: 0.008840814490827758\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005612626779251373\n",
      "SEED: 2, FOLD: 2, EPOCH: 16, train_loss: 0.00881868931213142\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005591073360007543\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.5883299143531838\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.09126324435839286\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.01658196109221191\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006127215026376339\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.009327689261251205\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.0057743099303199695\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.009258728411451384\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005670176210025182\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.009029878926387912\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.006187319254072813\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.008943139436981967\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0055402605794370174\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.008927012768548888\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005601270554157404\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.008883062573904926\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0057974918029056145\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.008898427697351656\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.0057203829861604254\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.008895004753375778\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.00550327765253874\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.008911207708454615\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.0056917797415875476\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.00889632959749449\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005579286899704199\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.008892917879731269\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005585258862433525\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.008877028465724073\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0055562673996274285\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.00887483245114217\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005575374735949131\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.008856654387420497\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005669305065216927\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.5873828723623946\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08586377593187186\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.01653062003488476\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0059788251080765175\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.0093736042948188\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.0061367300625603935\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.00948647059802268\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005539750966888208\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.0090909973919593\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005927860736846924\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.008992711503713115\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005804599979175971\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.008984287420438754\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005490336280602675\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.008953783755517891\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005417823003461728\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.008932911929347226\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005577935407368036\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.008932139126684618\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005462441665048783\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.008922239155131014\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005474580129465232\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.008914087873858374\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005416088880827794\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.008904968526818463\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005524482148197981\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.008892966119723546\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005479469859542755\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.008904169659709206\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005485089173397193\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.008885237275043855\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005425398882765036\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.5871590628615908\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07777635122721012\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.016588814745380265\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.0064587774328314345\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.009342811838094447\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005906288583691304\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.009180401288274978\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005768675679484239\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.009008879722977007\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005784031039533706\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.008958190666964731\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005497548514260695\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.008898542344419134\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.00571681003874311\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.008896785681261806\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005450628088930478\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.008885782105042725\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0055443554615172055\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.008890860827287307\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.00559578538657381\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.00890731392428279\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005533497852201645\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.008920686225079605\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005591789296326729\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.008911270899949846\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.00553956194422566\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.008909932627166444\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005530455257170475\n",
      "SEED: 2, FOLD: 5, EPOCH: 14, train_loss: 0.00887513261389088\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005647238272313888\n",
      "SEED: 2, FOLD: 5, EPOCH: 15, train_loss: 0.008869637389088402\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005587540960942323\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.589591762101328\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07007928765737094\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.016601298570733617\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.005995080842135044\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.009336015989852918\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.0056817826385108326\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.009203319274191116\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005403387037893901\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.00912125236228914\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005373791361657472\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.008961790650327867\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005798462205208265\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.008926444051384524\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.00526806740806653\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.00891565579946178\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005389663014704218\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.008902356991343\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005428136183092227\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.008899266636502501\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005359812138172297\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.008932870623932497\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005412656133278058\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.00894795497879386\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.00549288119117801\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.0089275042299886\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005473896646155761\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.008921984998458947\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005500288536915412\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.008920140589612562\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005390874289262753\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.008879235404468066\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005367495191211884\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.5864740016089903\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08506718220619056\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.0166205528846665\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006188073589538152\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.00929325382300728\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005771550528991681\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.00921583185727532\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005972583563281939\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.009086450700320908\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005639708959139311\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.0089620705945669\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005717512685805559\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.008917391079956212\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.00556339373668799\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.008917123003787285\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00543514581827017\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.008897347331701501\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005519025278492616\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.008891994882425343\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005639486695424869\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.008899300881485278\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005535565495777588\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.008883299469645764\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.00557556114374445\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.008897494688328053\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005588619325023431\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.008880247953473716\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005590791849849315\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.008885962391473554\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005592002175175226\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.008881351646237276\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005538909696042538\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.5891546818452913\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07099301769183232\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.017126160849993292\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.005988631218385238\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.00928530572737391\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005890773860021279\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.009500660002231598\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005586153326126246\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.009124252202643736\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.006409484678162978\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.00901357428095228\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0057316679650774366\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.00897972528646524\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.006076959391626028\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.008961513361616715\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005749231598411615\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.008944254871961233\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005610060340796526\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.008929055888910551\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005611721032227461\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.008941329971610292\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005629985127598047\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.008931268793153199\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005605410211361372\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.00891356513130705\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005612108534058699\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.008903198541972685\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005641161177593928\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.5883567281872839\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.09118524251075891\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.016606855004824495\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006198574788868427\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.009278193921656222\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005872939068537492\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.009660314655283818\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005777078931434796\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.009079914602979616\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005600909809940136\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.008971359555584353\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005551784156033626\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.008939504573071326\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005538510409398721\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.00891597431807502\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0057162800087378575\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.008920283088259198\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.00567363052127453\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.008908981123838472\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005510457397366946\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.008911759013662467\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005602047205544435\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.008904452322403321\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005536153518523161\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.008908347692340612\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005548181836135113\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.008879827580892959\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005539353113048351\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.00886771854365597\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005548894226264495\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.008870910110606535\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005579021436950335\n",
      "SEED: 3, FOLD: 2, EPOCH: 16, train_loss: 0.008842199084323805\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005528217181563377\n",
      "SEED: 3, FOLD: 2, EPOCH: 17, train_loss: 0.008822807639434532\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 17, valid_loss: 0.005512329427382121\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.5896466640201775\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08580870410570732\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.017265275485712935\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0059804851905657696\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.009254902135580778\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005652798948666224\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.011518200985281854\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.04344016671753847\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.009378263399609038\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005339636252476619\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.009080263937043177\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005366783732405076\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.00901788829926502\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.00545174191490962\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.008988083453496566\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005461651222923627\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.00896049354451935\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005459103231819777\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.008932518502193931\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005365226919261308\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.008950068011275819\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005452156281815126\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.008935208275058382\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005415695361219919\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.008906095036985102\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005403788939404946\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.008913730321502363\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0054470043127926495\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.5885625780635589\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08367907542448777\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.016640829274783265\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006748530118224712\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.00941765051637147\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.0060311372105318764\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.009225868714369229\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005565428640693426\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.009014422350839988\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005713937123521016\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.008977714988931611\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005551288477503336\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.008942607343448577\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005440587715174143\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.008906554160136226\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.00554861593991518\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.008897427016416111\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.0057236418629495\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.008889251608854613\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005586115929942865\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.008895413541058833\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005667726867474043\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.008888429584535392\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.00581479649274395\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.008888586046727927\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0056026035633224705\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.008896164369542856\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005654195180306068\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.008868715140616169\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005638705853086252\n",
      "SEED: 3, FOLD: 4, EPOCH: 15, train_loss: 0.008856483609289737\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005647385098899786\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.5891425366941336\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07789693371607707\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.01691139958849227\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.00598165554066117\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.009850737085012166\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005570905927855235\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.009130281333282992\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.032297942285927445\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.009200146295935721\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005956797645642207\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.008970148565650388\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005461264473314469\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.008930842606099072\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005311332463931579\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.008913472143782152\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.0057280504216368384\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.008922734580984389\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.00546036334708333\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.008921372112692208\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005470819377268736\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.00892580661142396\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005492371614449299\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.008896291350341728\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005416165535839705\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.008917049787988936\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005571712739765644\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.008910532505880739\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005366958068827024\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.008885459848553748\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.00549807850844585\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.5885406917816883\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07914890750096394\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.01664872281253338\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.00602556005693399\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.009260976473121223\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.006183272406745415\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.010391679101598423\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.00761613271270807\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.009213883530449224\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0055602152760212235\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.009012254829694694\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005575351990186251\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.008985716050390053\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005546296266122506\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.009001789513874698\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005526447883592202\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.008975271941036792\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005572218627024155\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.008964326824187427\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005639349755186301\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.008958488576919646\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005600567226513074\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.008949584440907111\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005648332612159161\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.008937947087090564\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005518350965128495\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.008915032430023357\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005503026267083792\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.008900994623734339\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005621626149289883\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.008876028187522615\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005560754798352718\n",
      "SEED: 3, FOLD: 6, EPOCH: 16, train_loss: 0.008851098362356424\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 16, valid_loss: 0.005622541102079244\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.5875022482831735\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0859022312439405\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.016891126483175402\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006081615897038808\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.009342465574878294\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005761021891465554\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.009199227055383695\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005563033314851614\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.009041485804561022\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005661812216903155\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.009064814522610726\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005504696486661067\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.008921079595598418\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005540018435567617\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.008919764102461774\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005587786686821626\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.008919999437608026\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005663341233650079\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.008900375438954783\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005540898463760431\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.008880213211366051\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005615235628703466\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.008893078388142827\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005502688805930889\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.008893110267062848\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005549619869830517\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.008865788994306649\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005559692016014686\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.008869283436168288\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.00553318252786994\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.008855557371232961\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005592307720619898\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.588213863505705\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07909926772117615\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.0167108961204822\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006076723516273957\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.009334149405460906\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005780195029309163\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.009517066910661556\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.0061608162135458906\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.00908296913965731\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005619124688494664\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.00900514522642904\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005519839648443919\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.00896451117571544\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0056703002908482\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.00895418635745709\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00561008401788198\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.008941606813538316\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005559855713867224\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.008940911537187325\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005631828716454597\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.00891580491175724\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005468797153578355\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.008901855190964165\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005594891030341387\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.008909044208357463\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005595946111358129\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.008899445255362504\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.0055406376217993405\n",
      "SEED: 4, FOLD: 1, EPOCH: 14, train_loss: 0.008897421780872989\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 14, valid_loss: 0.0055194178667779155\n",
      "SEED: 4, FOLD: 1, EPOCH: 15, train_loss: 0.00886556673543276\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005532476943559372\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.587037068263099\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08466200186656071\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.016478369692088785\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.0060842498563803155\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.009303460250029693\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005799115850375249\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.009222432788511788\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005596778104798152\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.009042876999120455\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01781959867534729\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.009000314129013065\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005633679612611349\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.008937626246463609\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0055549259369189925\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.008901100593140802\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005478334648964496\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.00890817684498993\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005608118282487759\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.008904587559250964\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005584042053669691\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.008883116552857933\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005581410136073828\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.008891137895753255\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005569190646593387\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.008880930568871868\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.0056018933223990295\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.00888262174998385\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.0055974330753088\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.008865348485021575\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005570637456213052\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: 0.008848093733241831\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: 0.00559012359008193\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.587303901947028\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.086477769108919\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.01684857889808513\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061521116429223465\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.009320429236804312\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.00586542970715807\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.009405931558560681\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005657069886533113\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.009119761918948309\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.0056925005494402004\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.009015064397071665\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.006321686499107342\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.008972968855822409\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0059009706243299525\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.00893860065529274\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00593186470751579\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.008935119138678184\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005604908264313753\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.008913428900209634\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005663224424307163\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.008901065794398656\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005568335799930187\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.008894037719614603\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005667964641291361\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.008876700256321882\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005594671417314272\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.008863869758725568\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005743860267102718\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.00887684675084578\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005660185841127084\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: nan\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: nan\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.5865931000459839\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08050820116813366\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.01667826180975582\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006039136232664952\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.009308006866155443\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005679100608596435\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.01050169874184035\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005532867454278927\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.00921025816854593\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0054341359780384945\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.009032996755244362\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005465349898888514\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.00958040400055816\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005788843326557141\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.009186466004246392\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005568748483291039\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.00905156710713699\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005514322672612392\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.009038125762615251\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005407986660989432\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.009003975139175719\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005502274725586176\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.00897451870244097\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005742373159871652\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.008958276304592555\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005454291159716936\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.008936733756264722\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005461523846651499\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.008911338924254114\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005377353491404882\n",
      "SEED: 4, FOLD: 4, EPOCH: 15, train_loss: 0.008895361846363222\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 15, valid_loss: 0.00545996527832288\n",
      "SEED: 4, FOLD: 4, EPOCH: 16, train_loss: 0.008867030082320844\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 16, valid_loss: 0.0054371047120254775\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.5875242160180131\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08188893932562608\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.016895706576572078\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.005915064543772202\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.00927159547604419\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005587695202288719\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.013444447084455876\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005496199493511365\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.00925514948982242\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005439647831595861\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.009048884205922886\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005421866913541005\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.008993605642604667\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005559447293098156\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.008988352832258554\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.0054364785766945435\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.008971188274035985\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005386293686639804\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.008946133060129108\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005399593510306799\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.008910664879540736\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005404203163030056\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.008907392828700107\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.0054805496922479225\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.008892179768834566\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.0055184248261726816\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.008883590117801685\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005488071662302201\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.008858379706539013\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005465691228612111\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.008834280923159944\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005496533408474464\n",
      "SEED: 4, FOLD: 5, EPOCH: 16, train_loss: 0.008806396558931147\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005455135296170528\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.5877114462892752\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08810798021463248\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.016602217106500994\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006066831581007976\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.009282255545258522\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005663614720106125\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.00919674547087099\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005695267078968195\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.009213681659988454\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005530319069153988\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.009000715516457284\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.0056623476557433605\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.00892802663902576\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005388750981252927\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.008905803287603162\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.0054579497888111155\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.008922722907988605\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.0054092719219625\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.008919654565083014\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005441665040472379\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.008900632534327137\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005564410991680164\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.008897459071532294\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.0054326166685384055\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.008899012221828909\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005496744854519\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.008883212686742883\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005464725375462037\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.008884388380809813\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.00542291053212606\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.5884394942707306\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08331875044565934\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.0164706450131898\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0060836088198881885\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.009262901806348079\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005704246604671845\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.009195268733074536\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005721823419802464\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.00904248289864611\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.00564493453846528\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.00896156846696662\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005543779008663618\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.008913320728351135\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005499344820586534\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.008886474568547832\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005501845779900367\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.008912860384412311\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005365678324149205\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.008914596778718201\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005452505778521299\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.008923920720966684\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005485691918203464\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.008907299079756075\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005513886168885689\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.008920328137842385\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005559930470413887\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.008904736029688973\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005562556226952718\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.008903397152804443\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005535623488517908\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: nan\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: nan\n",
      "SEED: 5, FOLD: 0, EPOCH: 16, train_loss: nan\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 16, valid_loss: nan\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.5883245318121201\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08233569963620259\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.016617913818540605\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.005979723941821318\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.009295690175447915\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005618955223606183\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.009841665952793649\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005516104221057434\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.009100937133503927\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.00561063177883625\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.009026393961362742\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.00564799031529289\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.008973750625611157\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005610980236759553\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.008949452847544406\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005542478559968563\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.008938913095138362\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005476337248602739\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.008932301585839407\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005479839988625967\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.008926373598090297\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00540678002513372\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.008904662014715172\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005413816776126623\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.008877469692379236\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005528648276455128\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.008880024756984534\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00548892102849025\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.008861302737952085\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005485425058465738\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.008834955943244937\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005474019652375808\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.5877562317292433\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08101062190074187\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.01664306881611009\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.00627955228376847\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.009335632058414253\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.006428909308921833\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.00916300790157874\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0208698225995669\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.009062282483068269\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005933513184292958\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.008973387969859145\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005713983438909054\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.00891571689548122\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005583092641945069\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.008903376946880205\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005493222485081508\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.008901456861781913\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.00557445462506551\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.008904078572585777\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005597971523037324\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.00889267510658986\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005671784102630157\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.008884792260171191\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005620388708149011\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.008885429303690389\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005630981929313678\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.008879829984712036\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005717575084418058\n",
      "SEED: 5, FOLD: 2, EPOCH: 14, train_loss: 0.008864155681048697\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005633623769076971\n",
      "SEED: 5, FOLD: 2, EPOCH: 15, train_loss: nan\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 15, valid_loss: nan\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.5877596319124505\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08278052164958073\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.016725284097766555\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006256592173415881\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.009339061918089519\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.00577966059343173\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.009341704206088104\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.00558481000077266\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.009078076254022686\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005818872891653042\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.008988031148407105\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005623325669708161\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.008916157713109578\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005662274332000659\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.008895891737444577\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005968456872953818\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.008904590617512932\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005660235989265717\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.008883551946161566\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005543378360856038\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.0088781441083631\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005525881997667826\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.008854401643966904\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005545718022263967\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.00887496497582745\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005601820141936724\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.008862022046201132\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005608779951356924\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.00885018426295672\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005516508164314123\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: 0.008828233398899838\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005544167405997331\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: 0.008823273451747122\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: 0.005526806227862835\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.5884007870949604\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08333978171531971\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.016561406198889017\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006033702037082269\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.009324089019886544\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005798444080238159\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.009255900941285733\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.00563981831790163\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.009034206008387578\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.006056827421371753\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.008944414241390454\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005380558888786114\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.008927100029698497\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005570067701717982\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.008913106731818738\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005559633450152783\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.008915110831023068\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005529427721809883\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.008910173997031274\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.00546679781893125\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.008901850861572736\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005471789600470891\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.00890858646331204\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005538901027578574\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.008906270528363215\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.00548785778049093\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.008890926963775544\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005574512367065136\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.008892456359053785\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.0054865882087212344\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.5886412042419653\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08067660721448752\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.016743597725557315\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006230141107852642\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.009283998943361882\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005854365953172629\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.009250750928815152\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.007140572899236129\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.009111951482859818\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005616018082946539\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.008977348765207303\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005478877323464706\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.008936140044416124\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005561371262256916\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.008920861622066917\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005603078788576217\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.008898469745307355\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0056200423994316505\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.008897146172318104\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005464666845420232\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.008885018231749937\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005454341880977154\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.008887729915865773\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005492634068314846\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.008886822864312577\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005483330012514041\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.008895353093189565\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005595705077911799\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.00886413049129014\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.00558765884488821\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.00883713416830712\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005529115872027783\n",
      "SEED: 5, FOLD: 5, EPOCH: 16, train_loss: 0.00884285322516351\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005546284732050621\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.5896372478958722\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.0921104561824065\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.01640301406685565\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.005939543533783693\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.00931060580989799\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005726212671456428\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.009454365467300286\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.0054416440498943515\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.009054164741993756\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005642735578406315\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.008967556386581949\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005458893540960092\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.008948791721785391\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005458605332443347\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.008933130947470263\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005409676724901566\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.008922784526303813\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.0054169762521409075\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.00892801204620785\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005325913805371294\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.00890877009746996\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.0054451846159421485\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.008912031721273387\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005407984261042797\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.008910997883995643\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005436344645344294\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.008896985519173983\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005407392620467222\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.008905366415510306\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005494506277430516\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: nan\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: nan\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.5882069529915178\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08577925941118827\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.016550692138136237\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0061941621466898005\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.00933025057452756\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005940109025686979\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.00922988512477762\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.00566196244639846\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.009082074553982631\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005597892611359174\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.008961352664423553\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.006632690676129782\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.00891657330951578\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005411871422368746\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.008909280342679168\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005473625344725756\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.008900924906688364\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005561883525493054\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.008914839149125525\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.0055681917673120135\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.008891096489655005\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.00557517958804965\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.00890531562067367\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.00560402784209985\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.008899100603082695\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005539995904725332\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.00888699570016281\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005536094701920564\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.008867689219580309\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005567300849809096\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.008873784851685568\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005563185227891574\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.5896202046927568\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07919212946524987\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.01732760512999989\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.005949664717683425\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.0094093673837346\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005698077094096404\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.009190541666907233\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005598077980371622\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.009091523375261474\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005645449094187755\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.008990694806483146\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005738549973242558\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.008946377154741739\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005440185885303295\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.008942312195997787\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005366783051823194\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.008928709405449193\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005536649340333847\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.008924652866364733\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005568483056357274\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.008925631919221298\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.0054930948938887855\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.008900239484737048\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005456913907367449\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.008901472379629677\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005515083097494566\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.008875733040071823\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00547893513710453\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.008857060349672227\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005503713762244353\n",
      "SEED: 6, FOLD: 1, EPOCH: 15, train_loss: 0.008860987202088172\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005478377239062236\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.5898729923206407\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08286448625417855\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.01672853490438413\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005942859042149324\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.00928430977856388\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005809645884885238\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.009252978148996024\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005662719934032514\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.009052260086645145\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005940919634527885\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.008964073630301533\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.0058196069171222355\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.008927776314620231\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005546384813407293\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.00892286659595934\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005559024221908588\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.008916422724723816\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005413034859185035\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.008898616107684132\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0054715745007762545\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.008897668663160625\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005439417221798346\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.008882975847636526\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0055407015964961965\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.008882304043131502\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005460113179511749\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.0088737294757487\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005502782547130034\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.008861988292050522\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005422016498274528\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.008837627442050222\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005497610948693294\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.5882340647481583\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08518419242822207\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.01676577241537539\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006049785010803204\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.009282055839493469\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005865753055191957\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.00916982172812159\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.006045668314282711\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.009032882976572256\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005610940046608448\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.008967004861128895\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005668328752597937\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.008939777784099852\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0057728522313902015\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.008921064996487788\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005856225768534036\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.008911460732437065\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005676884132509048\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.008918772130650846\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0057230772665486885\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.008918026783126028\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.00556541639021956\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.008915498072432505\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005703732192229766\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.008915396174415946\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005609246149945717\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.008908995074798932\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005649441100943547\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.008920063591889432\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005695985200313421\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.5891264854250727\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08708852701462232\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.016723320378947096\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.005972102069510863\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.009321640849717566\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005702105601533101\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.009238406399113906\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008559426650978051\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.009085470659507287\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005543018798702038\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.008986691755519525\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.0055701256586382026\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.0089414949415604\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.0056018011214641426\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.008931279987902255\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005551100314523165\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.008920763833196583\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005538992261370787\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.008905444866851778\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005506264941337017\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.008897253274414185\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0055539522033471326\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.008889743944982419\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005568052068925821\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.008888149218684112\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005566163418384699\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.008865332916832051\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005588908536502948\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.008838395405611073\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005625870544463396\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.008856107052919027\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005686840400672876\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.5886558408068644\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07486725082764259\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.016552975111817185\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006178058218210936\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.009445601998752839\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005630419338838412\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.009148109024642286\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005607647785487084\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.009019596816820873\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005747598309356432\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.008960099941169893\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.010931122689866103\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.008931341713193703\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.0054475379248078055\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.00891817853207121\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005541443502387175\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.008905992528574692\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005455086867396648\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.008908272777507836\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005578207711760814\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.00892332018151678\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005608713397612939\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.008928762912448193\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005605722526804759\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.008922505305727592\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005620018722346196\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.008893452049862291\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005593355028675153\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.008902515423156926\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005522789147037726\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.5868444994494721\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07966388246187797\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.016501807242732595\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006121794263330789\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.009352935213796995\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.00603561053195825\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.011148162374927386\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.009123353717418818\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.009280734745835935\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005390982609242201\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.009055277949350106\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005451692984654353\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.00899042033061788\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005474693249337948\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.008974796947645577\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005440560921740074\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.00895611963838943\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.0054994524599841004\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.008952033882205552\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005396313069818111\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.008920282452694467\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005469078592096384\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.008909252025438723\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005455707307331837\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.008908415515277837\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005455272415509591\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.00890061303318755\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005437478029097502\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test_[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:55:58.679453Z",
     "iopub.status.busy": "2020-11-29T08:55:58.677870Z",
     "iopub.status.idle": "2020-11-29T08:55:59.282587Z",
     "shell.execute_reply": "2020-11-29T08:55:59.281963Z"
    },
    "papermill": {
     "duration": 0.991872,
     "end_time": "2020-11-29T08:55:59.282722",
     "exception": false,
     "start_time": "2020-11-29T08:55:58.290850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "target = train[train_targets_scored.columns]\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:00.044391Z",
     "iopub.status.busy": "2020-11-29T08:56:00.042283Z",
     "iopub.status.idle": "2020-11-29T08:56:00.045147Z",
     "shell.execute_reply": "2020-11-29T08:56:00.045787Z"
    },
    "papermill": {
     "duration": 0.388301,
     "end_time": "2020-11-29T08:56:00.045939",
     "exception": false,
     "start_time": "2020-11-29T08:55:59.657638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id','kfold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:00.797853Z",
     "iopub.status.busy": "2020-11-29T08:56:00.796468Z",
     "iopub.status.idle": "2020-11-29T08:56:00.800666Z",
     "shell.execute_reply": "2020-11-29T08:56:00.801217Z"
    },
    "papermill": {
     "duration": 0.382806,
     "end_time": "2020-11-29T08:56:00.801378",
     "exception": false,
     "start_time": "2020-11-29T08:56:00.418572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:01.575186Z",
     "iopub.status.busy": "2020-11-29T08:56:01.573151Z",
     "iopub.status.idle": "2020-11-29T08:56:01.576004Z",
     "shell.execute_reply": "2020-11-29T08:56:01.576566Z"
    },
    "papermill": {
     "duration": 0.402693,
     "end_time": "2020-11-29T08:56:01.576709",
     "exception": false,
     "start_time": "2020-11-29T08:56:01.174016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:02.352853Z",
     "iopub.status.busy": "2020-11-29T08:56:02.341903Z",
     "iopub.status.idle": "2020-11-29T08:56:02.355922Z",
     "shell.execute_reply": "2020-11-29T08:56:02.355304Z"
    },
    "papermill": {
     "duration": 0.407027,
     "end_time": "2020-11-29T08:56:02.356038",
     "exception": false,
     "start_time": "2020-11-29T08:56:01.949011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7,random_state=seed)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_scored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_scored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:03.131433Z",
     "iopub.status.busy": "2020-11-29T08:56:03.130358Z",
     "iopub.status.idle": "2020-11-29T08:56:03.133652Z",
     "shell.execute_reply": "2020-11-29T08:56:03.133069Z"
    },
    "papermill": {
     "duration": 0.406813,
     "end_time": "2020-11-29T08:56:03.133782",
     "exception": false,
     "start_time": "2020-11-29T08:56:02.726969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:56:03.895454Z",
     "iopub.status.busy": "2020-11-29T08:56:03.893736Z",
     "iopub.status.idle": "2020-11-29T09:41:16.704701Z",
     "shell.execute_reply": "2020-11-29T09:41:16.703372Z"
    },
    "papermill": {
     "duration": 2713.195979,
     "end_time": "2020-11-29T09:41:16.704843",
     "exception": false,
     "start_time": "2020-11-29T08:56:03.508864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.5854889818945447\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.096135485630769\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.029538276781504218\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020154908729287293\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.021817868323744955\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01848551630973816\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.021159164104107266\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01823759824037552\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.02034663041499821\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.029917903817616977\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.02040479380033306\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017224487776939686\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.02004971538947241\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01722749236684579\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.020052638710350602\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01726303407205985\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.0199082541858425\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01725450516320192\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.019881514933060954\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01710408768401696\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.019839903163547452\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016958822567875568\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.01982094324823167\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01734642483867132\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.019807030094435085\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01687272251225435\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.019620104994926904\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016769622524197284\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.019503936372898722\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016588311570768174\n",
      "SEED: 0, FOLD: 0, EPOCH: 15, train_loss: 0.019304056349839713\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016513974190904543\n",
      "SEED: 0, FOLD: 0, EPOCH: 16, train_loss: 0.019151709671761538\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016603015148295805\n",
      "SEED: 0, FOLD: 0, EPOCH: 17, train_loss: 0.018970503295595582\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016454061564917747\n",
      "SEED: 0, FOLD: 0, EPOCH: 18, train_loss: 0.018707506786528473\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01637032821487922\n",
      "SEED: 0, FOLD: 0, EPOCH: 19, train_loss: 0.018355672574929288\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016326853432334386\n",
      "SEED: 0, FOLD: 0, EPOCH: 20, train_loss: 0.018014648853725678\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01609947424955093\n",
      "SEED: 0, FOLD: 0, EPOCH: 21, train_loss: 0.017579745828501275\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016067386604845524\n",
      "SEED: 0, FOLD: 0, EPOCH: 22, train_loss: 0.017185910932115606\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01603061447923\n",
      "SEED: 0, FOLD: 0, EPOCH: 23, train_loss: 0.01684474794043077\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016003005636426117\n",
      "SEED: 0, FOLD: 0, EPOCH: 24, train_loss: 0.016569760514775645\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015974216521359406\n",
      "SEED: 0, FOLD: 0, EPOCH: 25, train_loss: 0.01645509760222725\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01597975201618213\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.5868844532886067\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08708354486868931\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.029639833606779575\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02025610752976858\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.02189205715281738\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018984984893065233\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.021111621596925968\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.019466341401521977\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.020571142334390332\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.0183559746409838\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.020153451509572363\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017647849682431955\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.020209084466301108\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01730821682856633\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.019968122218710346\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017760389269544527\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.01994693435325816\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01794957097333211\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.019900524560865517\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017017673557767503\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.019816825845958414\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017038260514919575\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.019783878573090642\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017051472830084655\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.019694177509361022\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01690174066103422\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.019655294162598817\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01686610417583814\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.019473313983227755\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016848557270490207\n",
      "SEED: 0, FOLD: 1, EPOCH: 15, train_loss: 0.01931357758774145\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01670621385654578\n",
      "SEED: 0, FOLD: 1, EPOCH: 16, train_loss: 0.01907873244301693\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016582914914649267\n",
      "SEED: 0, FOLD: 1, EPOCH: 17, train_loss: 0.018806129593301465\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016456081317021296\n",
      "SEED: 0, FOLD: 1, EPOCH: 18, train_loss: 0.018519777703929593\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016359177919534538\n",
      "SEED: 0, FOLD: 1, EPOCH: 19, train_loss: 0.018217747653456958\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016406755464581344\n",
      "SEED: 0, FOLD: 1, EPOCH: 20, train_loss: 0.017861193624904025\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016239045474391717\n",
      "SEED: 0, FOLD: 1, EPOCH: 21, train_loss: 0.017418752474760688\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01626810087607457\n",
      "SEED: 0, FOLD: 1, EPOCH: 22, train_loss: 0.017001589974136772\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016182298986957624\n",
      "SEED: 0, FOLD: 1, EPOCH: 23, train_loss: 0.016616743813092645\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016180293133052494\n",
      "SEED: 0, FOLD: 1, EPOCH: 24, train_loss: 0.0163357973702856\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016177299360816296\n",
      "SEED: 0, FOLD: 1, EPOCH: 25, train_loss: 0.01619027698462879\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 25, valid_loss: 0.01616203892402924\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.5874656936204111\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08642379939556122\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.029751984276682943\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01998930238187313\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.02204649127717759\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018263164191291884\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.021103238988969777\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017860142155908622\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.020395703915808652\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017426952074926633\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.02015262487268931\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01967604558628339\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.020128618044829048\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016940454092736427\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.019976166504863148\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01715033773619395\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.019941938940334965\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01675195196786752\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.01993957836482976\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017002301290631294\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.019949115334531746\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017048091269456424\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.019894393186110096\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01709174723006212\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.019748130284652516\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016598549026709337\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.019655220990849508\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01667015254497528\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.01948678191449191\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016792607995179985\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.01937915583619395\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01645068723994952\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.01913050844057186\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016503227014954273\n",
      "SEED: 0, FOLD: 2, EPOCH: 17, train_loss: 0.01890577469021082\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016427160885471564\n",
      "SEED: 0, FOLD: 2, EPOCH: 18, train_loss: 0.018684694518309994\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016249098671743505\n",
      "SEED: 0, FOLD: 2, EPOCH: 19, train_loss: 0.01829760055989027\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016179097028305896\n",
      "SEED: 0, FOLD: 2, EPOCH: 20, train_loss: 0.017939191210914304\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016161896789876316\n",
      "SEED: 0, FOLD: 2, EPOCH: 21, train_loss: 0.01756843922005312\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016010202539081756\n",
      "SEED: 0, FOLD: 2, EPOCH: 22, train_loss: 0.01716808879093544\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01597193764665952\n",
      "SEED: 0, FOLD: 2, EPOCH: 23, train_loss: 0.01676384694370869\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01592839817301585\n",
      "SEED: 0, FOLD: 2, EPOCH: 24, train_loss: 0.01649461003221773\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015962317657585327\n",
      "SEED: 0, FOLD: 2, EPOCH: 25, train_loss: 0.016387584078050143\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 25, valid_loss: 0.01595665106120018\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.5868107586897708\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08537798661452073\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.029456612200954475\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019988307586083047\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.02181353110417321\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01839854783163621\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.0218045775703079\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018239105979983624\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.020388367837546644\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01761699467897415\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.020127969240215985\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01827712056155388\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.01999427536754189\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017276784405112267\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.020001903830750567\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01733282967828787\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.019945907507192443\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01748821812753494\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.019891885386125463\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017427100871617977\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.01991133198041368\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016941488935397223\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.019795871918668616\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017061767526544057\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.019683190294214198\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016915760504511688\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.019608122674194543\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01689758266393955\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.01953693899653248\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01690439894222296\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.01929834545464129\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016885412570375662\n",
      "SEED: 0, FOLD: 3, EPOCH: 16, train_loss: 0.019124463301252673\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01668988146747534\n",
      "SEED: 0, FOLD: 3, EPOCH: 17, train_loss: 0.018889580173669634\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01639813965616318\n",
      "SEED: 0, FOLD: 3, EPOCH: 18, train_loss: 0.01859140662929496\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 18, valid_loss: 0.0164524306758092\n",
      "SEED: 0, FOLD: 3, EPOCH: 19, train_loss: 0.0182257015006365\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01627914600360852\n",
      "SEED: 0, FOLD: 3, EPOCH: 20, train_loss: 0.01792392706045428\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01620792246495302\n",
      "SEED: 0, FOLD: 3, EPOCH: 21, train_loss: 0.01742848998086678\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016217511147260666\n",
      "SEED: 0, FOLD: 3, EPOCH: 22, train_loss: 0.01699710068469112\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016246294029630147\n",
      "SEED: 0, FOLD: 3, EPOCH: 23, train_loss: 0.016591516449242026\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016159512245884307\n",
      "SEED: 0, FOLD: 3, EPOCH: 24, train_loss: 0.016292332973633264\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016225988475176003\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.5880133756310553\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08986250196511929\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.02968339642157426\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019781226722093728\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.021804117169734592\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01864021995033209\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.022173739869046857\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.019041792704508856\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.020595743547420244\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01729411044372962\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.02027760964591761\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01723370744058719\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.020128823741263634\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017275581924388043\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.020029443290990753\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0170387879300576\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.020031702503360605\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016953929184147946\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.019982416358952586\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017493457318498537\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.01990836304990021\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017025437779151477\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.01991950667689781\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016714508430315897\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.01975442182171989\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016795334692757864\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.019650622019292536\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016745072717850026\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.019560317156483997\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01656648559639087\n",
      "SEED: 0, FOLD: 4, EPOCH: 15, train_loss: 0.019368904718273395\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016512489447800014\n",
      "SEED: 0, FOLD: 4, EPOCH: 16, train_loss: 0.01916291846616848\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016257415597255413\n",
      "SEED: 0, FOLD: 4, EPOCH: 17, train_loss: 0.01895151735358947\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01628481374623684\n",
      "SEED: 0, FOLD: 4, EPOCH: 18, train_loss: 0.018664525041507708\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016250003988926228\n",
      "SEED: 0, FOLD: 4, EPOCH: 19, train_loss: 0.018367344790415185\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01603974000765727\n",
      "SEED: 0, FOLD: 4, EPOCH: 20, train_loss: 0.017939909663353418\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015914248804060314\n",
      "SEED: 0, FOLD: 4, EPOCH: 21, train_loss: 0.017532925549391155\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015925511216314938\n",
      "SEED: 0, FOLD: 4, EPOCH: 22, train_loss: 0.0171045177817546\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015830929964207686\n",
      "SEED: 0, FOLD: 4, EPOCH: 23, train_loss: 0.01669750110925855\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01581172516139654\n",
      "SEED: 0, FOLD: 4, EPOCH: 24, train_loss: 0.016376000388550596\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01581263864556184\n",
      "SEED: 0, FOLD: 4, EPOCH: 25, train_loss: 0.016259465492456347\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01580502028362109\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.5878864689855963\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07786424859211995\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.029450130397202196\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.019681498121756773\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.02183342005151349\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018265325719347365\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.021166609499502827\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017391809190695103\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.020422004842879\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017182298004627228\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.020191623527254607\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.016829611446995\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.020083095450457687\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017046186643151138\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.020042896170068433\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017088880977378443\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.02005869016756077\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016861111355515625\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.01999560298045745\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016770187192238294\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.019925624258010775\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01658836702028146\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.019869775511324406\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016635134529608946\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.019760141023308843\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016812610798157178\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.01968955195735435\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016629714948626664\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.019596651070625394\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016385285255427543\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.019340697675943375\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016285773366689682\n",
      "SEED: 0, FOLD: 5, EPOCH: 16, train_loss: 0.019210390645909955\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 16, valid_loss: 0.01627970737620042\n",
      "SEED: 0, FOLD: 5, EPOCH: 17, train_loss: 0.01895836171870296\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016203832239485703\n",
      "SEED: 0, FOLD: 5, EPOCH: 18, train_loss: 0.018653506992032397\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 18, valid_loss: 0.01596805381660278\n",
      "SEED: 0, FOLD: 5, EPOCH: 19, train_loss: 0.01832536716215514\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 19, valid_loss: 0.015955962383976348\n",
      "SEED: 0, FOLD: 5, EPOCH: 20, train_loss: 0.018001049329098816\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 20, valid_loss: 0.015811592985231143\n",
      "SEED: 0, FOLD: 5, EPOCH: 21, train_loss: 0.017588872437340183\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 21, valid_loss: 0.015815416136040136\n",
      "SEED: 0, FOLD: 5, EPOCH: 22, train_loss: 0.017150553383839293\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015696708112955093\n",
      "SEED: 0, FOLD: 5, EPOCH: 23, train_loss: 0.016791201221781807\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 23, valid_loss: 0.0156829349266795\n",
      "SEED: 0, FOLD: 5, EPOCH: 24, train_loss: 0.016534391778042994\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015686851138105758\n",
      "SEED: 0, FOLD: 5, EPOCH: 25, train_loss: 0.01643750864408306\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01568493927614047\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.5868757895722583\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09491586513244189\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.029825374030986347\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020260021663629092\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.02182157999659712\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018581476635657825\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.020993336909324735\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.018109612740003146\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.02040470006397447\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017496293267378442\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.02015494998242404\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01734559968687021\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.019994630553835147\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01788491540803359\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.019937974879065075\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01710360053067024\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.019921862067201652\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017171179302609883\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.019806721801492008\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017223379359795496\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.019801799182754917\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017092043533921242\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.01983569366102283\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017214471760850687\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.019752199459518935\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.017354536371735427\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.01962549989489285\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016955169634177134\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.019466747429121186\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01685041174865686\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.01928953665333825\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016847999623188607\n",
      "SEED: 0, FOLD: 6, EPOCH: 16, train_loss: 0.019081218017114175\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016662146179721907\n",
      "SEED: 0, FOLD: 6, EPOCH: 17, train_loss: 0.018889866316237965\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016596948727965355\n",
      "SEED: 0, FOLD: 6, EPOCH: 18, train_loss: 0.018590822312477474\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016608838421794083\n",
      "SEED: 0, FOLD: 6, EPOCH: 19, train_loss: 0.01823722367250436\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016459969588770315\n",
      "SEED: 0, FOLD: 6, EPOCH: 20, train_loss: 0.01789637066021159\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01645177101286558\n",
      "SEED: 0, FOLD: 6, EPOCH: 21, train_loss: 0.017542647676089325\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016278163100091312\n",
      "SEED: 0, FOLD: 6, EPOCH: 22, train_loss: 0.01711745640716037\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016285558661016133\n",
      "SEED: 0, FOLD: 6, EPOCH: 23, train_loss: 0.016742042832177232\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016256315991855584\n",
      "SEED: 0, FOLD: 6, EPOCH: 24, train_loss: 0.016505346394370537\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016210126404005747\n",
      "SEED: 0, FOLD: 6, EPOCH: 25, train_loss: 0.01639572828001267\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016200549613970976\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.5860769466773884\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08152621984481812\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.029489273457108316\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019671831853114642\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.021843530338358234\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.017948596236797478\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.020991001278162003\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017612606215362366\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.02035010830071327\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01729453971179632\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.02014464542672441\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017142850189254835\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.01994779152241913\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017351317076155774\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.01994262638224943\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017048248304770544\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.019948028254549246\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017052149758316003\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.019890945555793273\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01688146834763197\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.019866972884817702\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01710129865946678\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.01974637370959327\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016862812308737866\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.019660085187973204\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016770092770457268\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.01959589956882032\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016932445721557506\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.01942028631330342\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016773666398456462\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.019230843018237\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016587106869197808\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.019138635664775566\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016664009541273117\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.018803907080075226\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01639588026759716\n",
      "SEED: 1, FOLD: 0, EPOCH: 18, train_loss: 0.018552038340351067\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016298503686602298\n",
      "SEED: 1, FOLD: 0, EPOCH: 19, train_loss: 0.018222991150577326\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016264186169092473\n",
      "SEED: 1, FOLD: 0, EPOCH: 20, train_loss: 0.017848266817226604\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016166796907782555\n",
      "SEED: 1, FOLD: 0, EPOCH: 21, train_loss: 0.017433057413310617\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016185773106721733\n",
      "SEED: 1, FOLD: 0, EPOCH: 22, train_loss: 0.0169965845809595\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016070111726339046\n",
      "SEED: 1, FOLD: 0, EPOCH: 23, train_loss: 0.016610143819471467\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01614463350807245\n",
      "SEED: 1, FOLD: 0, EPOCH: 24, train_loss: 0.01634224066259088\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016132359822782185\n",
      "SEED: 1, FOLD: 0, EPOCH: 25, train_loss: 0.016212873374791565\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016107641661969516\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.5875595168688813\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07902117875906137\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.029797406665779447\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020014180300327446\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.021989324960756947\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01844776450441434\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.0210633265559335\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017423680410362206\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.020433971633178158\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01715519866691186\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.02018383434797461\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.016987856549139205\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.020075122397896404\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01693607236330326\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.019973542264385802\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017256722713892277\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.0199390216101263\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016803498881367538\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.01991748155371563\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01690120679827837\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.01989110013016978\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016788070519956257\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.019866525396906042\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016718631896835107\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.01971352500589313\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01657017757399724\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.01963187341351767\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01665061991661787\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.01953919871231994\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016488664138775606\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.019343182318718045\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016579061889877685\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.01921590870699367\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01631168433679984\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.018894591343563957\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016530555243102405\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.018654716100443055\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016075960288827237\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.0182923058400283\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016068158169778492\n",
      "SEED: 1, FOLD: 1, EPOCH: 20, train_loss: nan\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 20, valid_loss: nan\n",
      "SEED: 1, FOLD: 1, EPOCH: 21, train_loss: nan\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 21, valid_loss: nan\n",
      "SEED: 1, FOLD: 1, EPOCH: 22, train_loss: nan\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 22, valid_loss: nan\n",
      "SEED: 1, FOLD: 1, EPOCH: 23, train_loss: nan\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 23, valid_loss: nan\n",
      "SEED: 1, FOLD: 1, EPOCH: 24, train_loss: nan\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 24, valid_loss: nan\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.5886320038824469\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.09649195464757773\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.029554180700231244\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020047945758471124\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.0218602461438324\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.020454606041312218\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.021195188290565402\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017991131314864524\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.020685882861348422\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017461308636344396\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.02029508785218806\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017441284341307785\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.019960662199033273\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01734799877382242\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.020019894918879948\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01700343979665866\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.019928753552203242\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01730448122207935\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.019875574806654774\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017126106155606415\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.019860111479018186\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01709352132792656\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.01982809343954196\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017082923450149022\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.019750715459923487\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01675769643714795\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.019612340407597052\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016777779190586165\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.019473699651457167\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01696557694902787\n",
      "SEED: 1, FOLD: 2, EPOCH: 15, train_loss: 0.019349334988038282\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016530778688880112\n",
      "SEED: 1, FOLD: 2, EPOCH: 16, train_loss: 0.01908761330855054\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016553576319263533\n",
      "SEED: 1, FOLD: 2, EPOCH: 17, train_loss: 0.01882807303824135\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01655411161482334\n",
      "SEED: 1, FOLD: 2, EPOCH: 18, train_loss: 0.018572744636519534\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01633088570088148\n",
      "SEED: 1, FOLD: 2, EPOCH: 19, train_loss: 0.018228054801757272\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01618498212729509\n",
      "SEED: 1, FOLD: 2, EPOCH: 20, train_loss: 0.017898624259475117\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016180584207177162\n",
      "SEED: 1, FOLD: 2, EPOCH: 21, train_loss: 0.017495864096122818\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016126972981370412\n",
      "SEED: 1, FOLD: 2, EPOCH: 22, train_loss: 0.01707974652684218\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016030553799982254\n",
      "SEED: 1, FOLD: 2, EPOCH: 23, train_loss: 0.01667183412339639\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01602294625571141\n",
      "SEED: 1, FOLD: 2, EPOCH: 24, train_loss: 0.0164111073355417\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016020283532830384\n",
      "SEED: 1, FOLD: 2, EPOCH: 25, train_loss: 0.016283307690173388\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015994903846428946\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.58906308118556\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.09071316627355722\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.029458403511828667\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020006190698880415\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.021893208921962493\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.028397833212063864\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.02096953081923562\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018235080373974945\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.02035629764400624\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01991310314490245\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.020150045033644984\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017460737090844374\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.019949587716444117\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017303379968954966\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.019906942506094236\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01726041605266241\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.01986252501405574\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01747349535043423\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.019775222307322798\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01724181754084734\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.019829310476779938\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017229937876646336\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.019721895280117925\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01716144784138753\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.019665123366222188\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017103496222541884\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.019529278515963942\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017252406248679526\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.019401150956951285\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017031974230821315\n",
      "SEED: 1, FOLD: 3, EPOCH: 15, train_loss: 0.019259890566605167\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016897165574706517\n",
      "SEED: 1, FOLD: 3, EPOCH: 16, train_loss: 0.019025739282369614\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016690284157028563\n",
      "SEED: 1, FOLD: 3, EPOCH: 17, train_loss: 0.018775452759016206\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016705383475010212\n",
      "SEED: 1, FOLD: 3, EPOCH: 18, train_loss: 0.018529901432024466\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016521842433856085\n",
      "SEED: 1, FOLD: 3, EPOCH: 19, train_loss: 0.018166647569553274\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016582000857362382\n",
      "SEED: 1, FOLD: 3, EPOCH: 20, train_loss: 0.01779869820519879\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016382556337003525\n",
      "SEED: 1, FOLD: 3, EPOCH: 21, train_loss: 0.017375408369745757\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016392672147888403\n",
      "SEED: 1, FOLD: 3, EPOCH: 22, train_loss: 0.016955420588822784\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01632034334425743\n",
      "SEED: 1, FOLD: 3, EPOCH: 23, train_loss: 0.016565213319719642\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016267892689659044\n",
      "SEED: 1, FOLD: 3, EPOCH: 24, train_loss: 0.016300339667076193\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 24, valid_loss: 0.0162884399581414\n",
      "SEED: 1, FOLD: 3, EPOCH: 25, train_loss: 0.016189519831961072\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 25, valid_loss: 0.01628580352721306\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.5879842523183372\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.09047928223243126\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.02959285963427376\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01990775649364178\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.021837585177775974\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018622909457637712\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.02105602274674016\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01761152079472175\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.020341043058480765\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0172431251177421\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.02012119711552923\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017118377754321464\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.020000588828446093\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.018645479845312927\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.02002892638179096\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017123746040921945\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.01993954894007058\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01702453912450717\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.019882287830114365\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017030043097642753\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.019870917564509687\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016970596491144255\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.01981667512272661\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01688395770123372\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.019691977498901857\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016843906961954556\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.019581828769799824\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016724809574393127\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.01945074992506085\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016728324385789726\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.019330307941984485\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01671823013860446\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.01908705841649223\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016611450280134495\n",
      "SEED: 1, FOLD: 4, EPOCH: 17, train_loss: 0.01889045667406675\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01651664773145547\n",
      "SEED: 1, FOLD: 4, EPOCH: 18, train_loss: 0.01864442372744953\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016289967828645155\n",
      "SEED: 1, FOLD: 4, EPOCH: 19, train_loss: 0.018299475513600016\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01617576153232501\n",
      "SEED: 1, FOLD: 4, EPOCH: 20, train_loss: 0.017866650143185177\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016068838321818754\n",
      "SEED: 1, FOLD: 4, EPOCH: 21, train_loss: 0.017522742380262225\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01596879944778406\n",
      "SEED: 1, FOLD: 4, EPOCH: 22, train_loss: 0.017056386376655585\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015962205898876373\n",
      "SEED: 1, FOLD: 4, EPOCH: 23, train_loss: 0.016679401446536585\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01600839699117037\n",
      "SEED: 1, FOLD: 4, EPOCH: 24, train_loss: 0.01647593347808799\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 24, valid_loss: 0.0159301428267589\n",
      "SEED: 1, FOLD: 4, EPOCH: 25, train_loss: 0.016333015925074752\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01593434767654309\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.5873126764152501\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.09064660794459857\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.02982157526688801\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020405511156870768\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.021948237072777103\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.045227389925947555\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.021027601147825654\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.018920942424581602\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.021126127675981134\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017511039685744505\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.020357664850716654\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017929984973027155\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.02019978702269696\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017014601482794836\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.020038689587365936\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017098275801310174\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.020046643208007555\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016922718200546045\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.019926679572342215\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016955961401645955\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.01990415868223519\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016771147242532328\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.019784643944050814\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016970097803725645\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.019760924794182583\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.01689735112281946\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: 0.019698358090544068\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: 0.0167293855920434\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: 0.019563097808812116\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016588571982888076\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: 0.01937138951207335\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01649023721424433\n",
      "SEED: 1, FOLD: 5, EPOCH: 16, train_loss: 0.01920041469605388\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016386273890160598\n",
      "SEED: 1, FOLD: 5, EPOCH: 17, train_loss: 0.01893623510526644\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016206927096041348\n",
      "SEED: 1, FOLD: 5, EPOCH: 18, train_loss: 0.018672546598355513\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016202141960652974\n",
      "SEED: 1, FOLD: 5, EPOCH: 19, train_loss: 0.018404650703273916\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01605776812021549\n",
      "SEED: 1, FOLD: 5, EPOCH: 20, train_loss: 0.017988524097647215\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016168172256304666\n",
      "SEED: 1, FOLD: 5, EPOCH: 21, train_loss: 0.017570018868994067\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 21, valid_loss: 0.015998793980823114\n",
      "SEED: 1, FOLD: 5, EPOCH: 22, train_loss: 0.017162746170888078\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015974651019160565\n",
      "SEED: 1, FOLD: 5, EPOCH: 23, train_loss: 0.016788076521275012\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015929717427262895\n",
      "SEED: 1, FOLD: 5, EPOCH: 24, train_loss: 0.01651555663478133\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015916205727710173\n",
      "SEED: 1, FOLD: 5, EPOCH: 25, train_loss: 0.016428732514582777\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015898077891996272\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.5886495564434979\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.10343765582029636\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.030137052180597913\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019774526071089964\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.022026991043743248\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018258115706535485\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.021113450311728427\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017516520734016713\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.020483578907678258\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01737411391849701\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.02013995641892826\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.018220462191563386\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.02007023567283476\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01732032960997178\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.019923592061811202\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017375485971570015\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.01983927293504412\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.016877470108178947\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.019846483964372327\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.01686798329823292\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.019807559135999228\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.016789993414512046\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.01971972258006399\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.01668505334796814\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.019604288998085098\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016842325791143455\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.019536434496576723\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016906558607633296\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.01940784233345373\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016616838411069833\n",
      "SEED: 1, FOLD: 6, EPOCH: 15, train_loss: 0.019251590040889947\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01646609826443287\n",
      "SEED: 1, FOLD: 6, EPOCH: 16, train_loss: 0.01908465791997072\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016477202351849813\n",
      "SEED: 1, FOLD: 6, EPOCH: 17, train_loss: 0.018817287164966803\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01628809357778384\n",
      "SEED: 1, FOLD: 6, EPOCH: 18, train_loss: 0.018513746609961666\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01619692504979097\n",
      "SEED: 1, FOLD: 6, EPOCH: 19, train_loss: 0.018202077521867043\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01612048904196574\n",
      "SEED: 1, FOLD: 6, EPOCH: 20, train_loss: 0.01779935189296265\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016044182273057792\n",
      "SEED: 1, FOLD: 6, EPOCH: 21, train_loss: 0.017411737262296514\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 21, valid_loss: 0.015947144836760484\n",
      "SEED: 1, FOLD: 6, EPOCH: 22, train_loss: 0.01693140375553756\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 22, valid_loss: 0.015954031250797786\n",
      "SEED: 1, FOLD: 6, EPOCH: 23, train_loss: 0.01653224496623954\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 23, valid_loss: 0.0159293797153693\n",
      "SEED: 1, FOLD: 6, EPOCH: 24, train_loss: 0.0162809327798518\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01588591768477972\n",
      "SEED: 1, FOLD: 6, EPOCH: 25, train_loss: 0.016160284106091067\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 25, valid_loss: 0.01588614134547802\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.5875571630895138\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07756991340563847\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.029716529707248147\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019822957567297496\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.0219582919585141\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018415239138098862\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.020924555767025496\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017685091552826073\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.020317264152942476\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0172661949092379\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.0201373972955185\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017398848914756224\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.020042333172986638\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017606465719067134\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.019945204711040936\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01714649610221386\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.01992050314171089\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01714660212970697\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.019814556590407283\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01693460359596289\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.019852756497425003\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.0168984063112965\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.019763179500964848\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017005115174330197\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.01962634246494319\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01666146617096204\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.019489138462656253\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016777965096900098\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.019423423058076483\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016853524801822808\n",
      "SEED: 2, FOLD: 0, EPOCH: 15, train_loss: 0.019308685148889955\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016625880765227172\n",
      "SEED: 2, FOLD: 0, EPOCH: 16, train_loss: 0.019080659953524936\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016542246995063927\n",
      "SEED: 2, FOLD: 0, EPOCH: 17, train_loss: 0.018773834774824413\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016609430957872134\n",
      "SEED: 2, FOLD: 0, EPOCH: 18, train_loss: 0.01852372062165995\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01638307751944432\n",
      "SEED: 2, FOLD: 0, EPOCH: 19, train_loss: 0.01817085164775317\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016130903305915687\n",
      "SEED: 2, FOLD: 0, EPOCH: 20, train_loss: 0.01781135591099391\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01611230314637606\n",
      "SEED: 2, FOLD: 0, EPOCH: 21, train_loss: 0.017371562687126366\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01612780300470499\n",
      "SEED: 2, FOLD: 0, EPOCH: 22, train_loss: 0.016945070914320043\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015990172441189106\n",
      "SEED: 2, FOLD: 0, EPOCH: 23, train_loss: 0.016556117721405382\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01599222865815346\n",
      "SEED: 2, FOLD: 0, EPOCH: 24, train_loss: 0.016287199246722298\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015956909180833742\n",
      "SEED: 2, FOLD: 0, EPOCH: 25, train_loss: 0.016125781184716803\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01599078639768637\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.5864340337748463\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.10087786271021916\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.029737426320443284\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02007784264592024\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.02189766864820912\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.020079957464566596\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.021191675643864517\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01772019102309759\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.020689594785909395\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.20368514152673575\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.02099351617633491\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017547905516739074\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.020212996348335937\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017612190988774482\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.020053056874186605\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017252189107239246\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.020006866823579814\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017502749553666666\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.019997929399077956\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017066249050773107\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.0199568674622758\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017172304196999624\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.019756675144103734\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01697129154434571\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.01969184590553915\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016975289568878137\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.019665284661223758\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.017046388525229234\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.01941449393996516\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016742287346949943\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.019381475357993228\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016605067568329666\n",
      "SEED: 2, FOLD: 1, EPOCH: 16, train_loss: 0.01912506521251556\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016604469874157354\n",
      "SEED: 2, FOLD: 1, EPOCH: 17, train_loss: 0.018911561878347718\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016647839918732643\n",
      "SEED: 2, FOLD: 1, EPOCH: 18, train_loss: 0.018627134906883176\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01638992725370022\n",
      "SEED: 2, FOLD: 1, EPOCH: 19, train_loss: 0.018295699957053404\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016175566527705926\n",
      "SEED: 2, FOLD: 1, EPOCH: 20, train_loss: 0.017932617030030972\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01617620914028241\n",
      "SEED: 2, FOLD: 1, EPOCH: 21, train_loss: 0.01751363211991014\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016115085866588812\n",
      "SEED: 2, FOLD: 1, EPOCH: 22, train_loss: 0.017134534736239427\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016079902004164\n",
      "SEED: 2, FOLD: 1, EPOCH: 23, train_loss: 0.016726291713279648\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016098893892306548\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.5866171299807124\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08222652455935112\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.02957892868466474\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020097811348163165\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.021879431363698597\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01836464382134951\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.021283193264861364\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01742374008664718\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.02044779500244437\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017287285496982243\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.02011001666353361\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017466717614577368\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.019960827798255393\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017008064386363212\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.020024241829240643\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017072498583449766\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.019919486741560535\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016762416236675702\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.01993652991950512\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016840547394867126\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.019861911499016994\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01669605004672821\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.019805620600645606\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01681377846174515\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.019668673014117254\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016665305369175397\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.019619312842149992\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016590496095327232\n",
      "SEED: 2, FOLD: 2, EPOCH: 14, train_loss: 0.019454662008462725\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016645736419237576\n",
      "SEED: 2, FOLD: 2, EPOCH: 15, train_loss: 0.019355152960161905\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016422343726914663\n",
      "SEED: 2, FOLD: 2, EPOCH: 16, train_loss: 0.019132270930788002\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01638349167142923\n",
      "SEED: 2, FOLD: 2, EPOCH: 17, train_loss: 0.018882112753753726\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01618708870731867\n",
      "SEED: 2, FOLD: 2, EPOCH: 18, train_loss: 0.018620307960018918\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01621078821615531\n",
      "SEED: 2, FOLD: 2, EPOCH: 19, train_loss: 0.0182828854618443\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016130286268889904\n",
      "SEED: 2, FOLD: 2, EPOCH: 20, train_loss: 0.01788345324127255\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01601107339732922\n",
      "SEED: 2, FOLD: 2, EPOCH: 21, train_loss: 0.01743232280116629\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015983985378765143\n",
      "SEED: 2, FOLD: 2, EPOCH: 22, train_loss: 0.016992066294659634\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015906438303108398\n",
      "SEED: 2, FOLD: 2, EPOCH: 23, train_loss: 0.016599798184895032\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015889460865694743\n",
      "SEED: 2, FOLD: 2, EPOCH: 24, train_loss: 0.01633223138648916\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015837536551631413\n",
      "SEED: 2, FOLD: 2, EPOCH: 25, train_loss: 0.016184545386381245\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 25, valid_loss: 0.01586693425018054\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.5873866314823563\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07539414843687645\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.029465821898869565\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019808023165051755\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.022031620748945185\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02296518964263109\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.020974359827468526\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.021968759023226224\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.020531926933373953\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017920503106254797\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.020135190212041944\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017657300170797568\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.019947748329188372\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.018256818445829246\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.01991520409245749\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017198669652526196\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.019951292817052955\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01693355320737912\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.019829535982697398\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017034768771666747\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.019814098203504407\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017098952228060134\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.019729780234597826\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016766489268495485\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.01964931857042216\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016901184231615983\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.019689889070955483\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017060699514471568\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.019497084934767837\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01675237500323699\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.0192665999402871\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016704774748247404\n",
      "SEED: 2, FOLD: 3, EPOCH: 16, train_loss: 0.01909351781816096\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01652190275490284\n",
      "SEED: 2, FOLD: 3, EPOCH: 17, train_loss: 0.01884147894845621\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 17, valid_loss: 0.0164470998570323\n",
      "SEED: 2, FOLD: 3, EPOCH: 18, train_loss: 0.01853136660380138\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01644112506451515\n",
      "SEED: 2, FOLD: 3, EPOCH: 19, train_loss: 0.018198984675109386\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016394473970509492\n",
      "SEED: 2, FOLD: 3, EPOCH: 20, train_loss: 0.01777868559332313\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016194985677989628\n",
      "SEED: 2, FOLD: 3, EPOCH: 21, train_loss: 0.017331088679163036\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01608042949094222\n",
      "SEED: 2, FOLD: 3, EPOCH: 22, train_loss: 0.016930782349427808\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01610187512750809\n",
      "SEED: 2, FOLD: 3, EPOCH: 23, train_loss: 0.016476226165085227\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01611591366907725\n",
      "SEED: 2, FOLD: 3, EPOCH: 24, train_loss: 0.016191812672627134\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01605544790912133\n",
      "SEED: 2, FOLD: 3, EPOCH: 25, train_loss: 0.016085650041900778\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 25, valid_loss: 0.01608646338662276\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.5866417984503347\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.09664568706200673\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.02946554577431163\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020028957810539465\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.021723051001695363\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018825767991634514\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.021012967074843677\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01828844644702398\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.020319931209087372\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01769993769434782\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.020054193087727636\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01763466401742055\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.01996764598565327\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017884007583443936\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.01997412006194527\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01719693481349028\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.019899538114062837\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017204936737051375\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.01992291594679291\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016904456684222587\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.019792126693032885\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017181873894654788\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.01975598800423983\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01718493665640171\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.019767414400907787\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017093349821292438\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.019629810735381937\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.017001185996028092\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.019394917967351707\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01693202082354289\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.019400773695795924\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016778883882440053\n",
      "SEED: 2, FOLD: 4, EPOCH: 16, train_loss: 0.01916263297804304\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01675387486242331\n",
      "SEED: 2, FOLD: 4, EPOCH: 17, train_loss: 0.018909081640477117\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016571529424534395\n",
      "SEED: 2, FOLD: 4, EPOCH: 18, train_loss: 0.01860425659027454\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 18, valid_loss: 0.0164278126679934\n",
      "SEED: 2, FOLD: 4, EPOCH: 19, train_loss: 0.018312597722821945\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016357629416653745\n",
      "SEED: 2, FOLD: 4, EPOCH: 20, train_loss: 0.017906588275690336\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016378104973297853\n",
      "SEED: 2, FOLD: 4, EPOCH: 21, train_loss: 0.017506820300744998\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016232984283795722\n",
      "SEED: 2, FOLD: 4, EPOCH: 22, train_loss: 0.017067305655596225\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01614174977518045\n",
      "SEED: 2, FOLD: 4, EPOCH: 23, train_loss: 0.016682272437154443\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016156066853839617\n",
      "SEED: 2, FOLD: 4, EPOCH: 24, train_loss: 0.016467292918949515\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01614142245111557\n",
      "SEED: 2, FOLD: 4, EPOCH: 25, train_loss: 0.016300756421342894\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016122398611444693\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.5880641960413069\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.09557632127633461\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.029808603780897888\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.02007670757862238\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.021781075267574272\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018194534959128268\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.02107802008253497\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017874950256485205\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.02044158028690396\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017683580087927673\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.02025109944814766\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017327144025610045\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.020110875267434766\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.01745616580144717\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.01999691118662422\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.016967136341218766\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.019958553659553464\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017224139892137967\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.01994575557575838\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016737603295881014\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.019903482944780105\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016883441605246984\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.019833473790739034\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016919180034444883\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.019800535478704685\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.01671056177180547\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.019690665466761268\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016770993287746724\n",
      "SEED: 2, FOLD: 5, EPOCH: 14, train_loss: 0.01953728839352324\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 14, valid_loss: 0.01667675032065465\n",
      "SEED: 2, FOLD: 5, EPOCH: 15, train_loss: 0.019353392156394752\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016694399241644602\n",
      "SEED: 2, FOLD: 5, EPOCH: 16, train_loss: 0.01924070476780872\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016601386694953993\n",
      "SEED: 2, FOLD: 5, EPOCH: 17, train_loss: 0.01897191384656204\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016427876714330453\n",
      "SEED: 2, FOLD: 5, EPOCH: 18, train_loss: 0.01867261075892964\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016176948610406656\n",
      "SEED: 2, FOLD: 5, EPOCH: 19, train_loss: 0.01833261353139942\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016143380306088008\n",
      "SEED: 2, FOLD: 5, EPOCH: 20, train_loss: 0.01805417866420907\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016117706393393185\n",
      "SEED: 2, FOLD: 5, EPOCH: 21, train_loss: 0.01762931642902864\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01605998932455595\n",
      "SEED: 2, FOLD: 5, EPOCH: 22, train_loss: 0.017244624225674448\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015971030466831647\n",
      "SEED: 2, FOLD: 5, EPOCH: 23, train_loss: 0.01690960642755837\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015935469705324907\n",
      "SEED: 2, FOLD: 5, EPOCH: 24, train_loss: 0.01664094499790588\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015921816086539857\n",
      "SEED: 2, FOLD: 5, EPOCH: 25, train_loss: 0.016575397822905232\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015949307654339533\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.5870968934047867\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09365474260770358\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.02969509395896583\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.01965266466140747\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.02185963187366724\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018664224789692804\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.021760349539486138\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017598604496855002\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.020469004363828414\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017470761130635556\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.020266576141521737\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017089979723095894\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.02009350758650013\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017293489036651757\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.020003411138581263\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01703240808386069\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.019989789413237893\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017306286125228956\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.019860414939152228\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.016960515139194634\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.01988671370152686\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017056061671330378\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.01988884071643288\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016813400559700452\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.0197319197594314\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01670172316237138\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.019598395865712617\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016648244542571213\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.019528412763532753\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01660395900790508\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.019387517778857333\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01649531851021143\n",
      "SEED: 2, FOLD: 6, EPOCH: 16, train_loss: 0.019140465889830847\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016328278857354935\n",
      "SEED: 2, FOLD: 6, EPOCH: 17, train_loss: 0.018883284055502027\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016381621933900394\n",
      "SEED: 2, FOLD: 6, EPOCH: 18, train_loss: 0.01867660296124381\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01617538112287338\n",
      "SEED: 2, FOLD: 6, EPOCH: 19, train_loss: 0.018280956692792272\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01614934356453327\n",
      "SEED: 2, FOLD: 6, EPOCH: 20, train_loss: 0.017987050569138012\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01610500652056474\n",
      "SEED: 2, FOLD: 6, EPOCH: 21, train_loss: 0.017522821983171476\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 21, valid_loss: 0.015949196468752164\n",
      "SEED: 2, FOLD: 6, EPOCH: 22, train_loss: 0.017019369840823317\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 22, valid_loss: 0.015963185435304277\n",
      "SEED: 2, FOLD: 6, EPOCH: 23, train_loss: 0.01663613469163711\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 23, valid_loss: 0.015901262871921062\n",
      "SEED: 2, FOLD: 6, EPOCH: 24, train_loss: 0.01633645245503332\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01588580635591195\n",
      "SEED: 2, FOLD: 6, EPOCH: 25, train_loss: 0.016195663842498452\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 25, valid_loss: 0.015902456612541124\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.586173727504305\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08721052626004586\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.029856316543914175\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02073518788585296\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.0217943159813011\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018873096372072514\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.02111958616690056\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.05861163683808767\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.020928023231996072\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017642097547650337\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.02021117795359444\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017459024030428667\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.0200734348413912\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01751244827531851\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.0199793931348501\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017377435587919675\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.019917655862062365\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017073106593810596\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.01985806624430257\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01736914638716441\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.01985984217576884\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017276700012958966\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.01972864628643603\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017107495608238075\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.019628985206017625\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01710947545675131\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.019571982550661306\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017137833656026766\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.019473166582552163\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.017085642625506107\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.019266668631619698\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016814645666342515\n",
      "SEED: 3, FOLD: 0, EPOCH: 16, train_loss: 0.01904863552064509\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01658448498122967\n",
      "SEED: 3, FOLD: 0, EPOCH: 17, train_loss: 0.01883631874177907\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01656429097056389\n",
      "SEED: 3, FOLD: 0, EPOCH: 18, train_loss: 0.01851759385317564\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016298921563877508\n",
      "SEED: 3, FOLD: 0, EPOCH: 19, train_loss: 0.018179548287613166\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016400235919998243\n",
      "SEED: 3, FOLD: 0, EPOCH: 20, train_loss: 0.017809467641888437\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016353308008267328\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.586510309999859\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.09369731465211281\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.02958455462814183\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01942156685086397\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.022078832082853123\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018131891981913492\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.020967514153469254\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017846804828597948\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.02038809682267743\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.018126628075081568\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.020159921281643817\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01683142723945471\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.020023223113369296\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0169168129706612\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.01990733582627129\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01683602310143984\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.01989662695071987\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016818268797718562\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.0199244382816392\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01673714494189391\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.019823272158769337\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016668732278048992\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.01978593020120988\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016584735865203235\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.0196557201797495\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016525053705733556\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.019619091942503646\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01643621355581742\n",
      "SEED: 3, FOLD: 1, EPOCH: 14, train_loss: 0.019480943201562843\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016438530399822272\n",
      "SEED: 3, FOLD: 1, EPOCH: 15, train_loss: 0.01929027385808326\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016311246042068187\n",
      "SEED: 3, FOLD: 1, EPOCH: 16, train_loss: 0.01908740889583085\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016279481781216767\n",
      "SEED: 3, FOLD: 1, EPOCH: 17, train_loss: 0.018904299273885584\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016107384043817338\n",
      "SEED: 3, FOLD: 1, EPOCH: 18, train_loss: 0.018548719610112743\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015984066045628145\n",
      "SEED: 3, FOLD: 1, EPOCH: 19, train_loss: 0.018226504149670537\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016028440199219264\n",
      "SEED: 3, FOLD: 1, EPOCH: 20, train_loss: 0.017863016323866072\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015926430073495094\n",
      "SEED: 3, FOLD: 1, EPOCH: 21, train_loss: 0.017401750098813226\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01585058380778019\n",
      "SEED: 3, FOLD: 1, EPOCH: 22, train_loss: 0.01702010501931245\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0157604984079416\n",
      "SEED: 3, FOLD: 1, EPOCH: 23, train_loss: 0.01664928954749091\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015742440421420794\n",
      "SEED: 3, FOLD: 1, EPOCH: 24, train_loss: 0.016377846987263578\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015765401964577343\n",
      "SEED: 3, FOLD: 1, EPOCH: 25, train_loss: 0.016254208478573208\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015742527679182015\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.5872113855706679\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07824716659692618\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.029736333501500053\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02024014050570818\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.021849940807835477\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018532498381458797\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.020959993346116028\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01793670138487449\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.02041796033547537\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017462345986412123\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.020171045829114075\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017223006687485255\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.01993400346789811\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016883169802335594\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.019975224132272037\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016950662032915995\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.019891384082871513\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.0169766485117949\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.019893490935902338\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0172595944828712\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.019906706201869087\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016848423160039462\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.01977055806767296\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016816994891716883\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.019761173910385853\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016899506059976723\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.019620994382814783\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016693459823727608\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.0194728007489765\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01663492276118352\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.019340010259199788\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01653842284129216\n",
      "SEED: 3, FOLD: 2, EPOCH: 16, train_loss: 0.019156963388259347\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016312604698424157\n",
      "SEED: 3, FOLD: 2, EPOCH: 17, train_loss: 0.01887681013023531\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01626294020276803\n",
      "SEED: 3, FOLD: 2, EPOCH: 18, train_loss: 0.01858303154743201\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016148056834936142\n",
      "SEED: 3, FOLD: 2, EPOCH: 19, train_loss: 0.018257958814501762\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01607081465996229\n",
      "SEED: 3, FOLD: 2, EPOCH: 20, train_loss: 0.017904974922940537\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015981661943862073\n",
      "SEED: 3, FOLD: 2, EPOCH: 21, train_loss: 0.017454645785226208\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015941906792040054\n",
      "SEED: 3, FOLD: 2, EPOCH: 22, train_loss: 0.017070120515150798\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015943248183108293\n",
      "SEED: 3, FOLD: 2, EPOCH: 23, train_loss: 0.01671101840061916\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015923329557363804\n",
      "SEED: 3, FOLD: 2, EPOCH: 24, train_loss: 0.016405469473652744\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01588546785597618\n",
      "SEED: 3, FOLD: 2, EPOCH: 25, train_loss: 0.016284461510745255\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 25, valid_loss: 0.01589707199197549\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.587276874663862\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.09224809591586773\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.029940108063857298\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020392449142841194\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.021896541471014153\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018491703157241527\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.021222839358489256\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.019890701971375026\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.020608906080392567\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01767686725809024\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.020121747376145544\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01763486432341429\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.020048883038799505\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017310540979871385\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.01994276776708461\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01718498207628727\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.019921035782710927\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017046121378930714\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.0198787406237947\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016809388135488216\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.019761152263428713\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017127023579982612\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.019733065110002015\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01681126611163983\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.019664702609785506\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016706328839063644\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.019549380283097963\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016687528015329287\n",
      "SEED: 3, FOLD: 3, EPOCH: 14, train_loss: 0.01944999150126367\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016667887281913023\n",
      "SEED: 3, FOLD: 3, EPOCH: 15, train_loss: 0.019292002871028474\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016534301165777903\n",
      "SEED: 3, FOLD: 3, EPOCH: 16, train_loss: 0.019039892163631077\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016362334315020304\n",
      "SEED: 3, FOLD: 3, EPOCH: 17, train_loss: 0.018910264772539202\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01642965367780282\n",
      "SEED: 3, FOLD: 3, EPOCH: 18, train_loss: 0.018545913610708068\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016339729038568642\n",
      "SEED: 3, FOLD: 3, EPOCH: 19, train_loss: 0.018264014676615998\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016101664648606226\n",
      "SEED: 3, FOLD: 3, EPOCH: 20, train_loss: 0.017795956391539122\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016061541839287832\n",
      "SEED: 3, FOLD: 3, EPOCH: 21, train_loss: 0.01740142301580793\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015972548307707675\n",
      "SEED: 3, FOLD: 3, EPOCH: 22, train_loss: 0.016967132813423068\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015970303462101862\n",
      "SEED: 3, FOLD: 3, EPOCH: 23, train_loss: 0.016564423344223887\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015957227621514063\n",
      "SEED: 3, FOLD: 3, EPOCH: 24, train_loss: 0.016275548225117696\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015927176349438153\n",
      "SEED: 3, FOLD: 3, EPOCH: 25, train_loss: 0.01617294499600256\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 25, valid_loss: 0.015916431680894814\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.5877167530156471\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.09730409773496482\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.02943385566106519\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019872583305606477\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.021708175263090712\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01976765921482673\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.020938728558453353\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017582943233159874\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.020315091578742943\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017515681110895596\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.020976633085189638\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.02177881119916072\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.020733751910361083\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01781092039667643\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.020218268313722032\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017243025537866812\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.02009795039791513\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017181894527031824\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.02004448226275476\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.0170545272815686\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.019911592851418095\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017077684975587405\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.01988534480836746\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01727145681014428\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.019760931917541736\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01711757380801898\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.01964016102657125\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01689186556121478\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.019527409829803416\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016927215485618666\n",
      "SEED: 3, FOLD: 4, EPOCH: 15, train_loss: 0.019359456098361594\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01674166278770337\n",
      "SEED: 3, FOLD: 4, EPOCH: 16, train_loss: 0.01919438413067444\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016707924051353566\n",
      "SEED: 3, FOLD: 4, EPOCH: 17, train_loss: 0.018972154455007734\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016531251227626435\n",
      "SEED: 3, FOLD: 4, EPOCH: 18, train_loss: 0.01871470973600407\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01658664708240674\n",
      "SEED: 3, FOLD: 4, EPOCH: 19, train_loss: 0.018369521618493506\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016412540697134458\n",
      "SEED: 3, FOLD: 4, EPOCH: 20, train_loss: 0.017958019910430587\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01634063270802681\n",
      "SEED: 3, FOLD: 4, EPOCH: 21, train_loss: 0.017571162986191543\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01623458443925931\n",
      "SEED: 3, FOLD: 4, EPOCH: 22, train_loss: 0.017185765419256042\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016236695890816357\n",
      "SEED: 3, FOLD: 4, EPOCH: 23, train_loss: 0.01678493615189517\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016183909601890124\n",
      "SEED: 3, FOLD: 4, EPOCH: 24, train_loss: 0.016526988619384734\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016202779630055793\n",
      "SEED: 3, FOLD: 4, EPOCH: 25, train_loss: 0.016399871092289686\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016178740546680413\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.5891933823759491\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.0899445592210843\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.029463577990394993\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020190238666075926\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.021740132414207265\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018545641348912165\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.02084434246392669\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017435559859642617\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.020354499134260254\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017438179168563623\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.020133059320820344\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017207706920229472\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.019912790884641377\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017344798821096238\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.01989690956936495\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.01691977780025739\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.019858908512302348\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017257701963759385\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.01989018637686968\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016923502589074466\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.019882659503334277\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016903426211613875\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.01979326952651546\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016831576036146052\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.01959116449831305\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.01686824865352649\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.019536495737328723\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016748684243513987\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.019441116047469346\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016643542008331187\n",
      "SEED: 3, FOLD: 5, EPOCH: 15, train_loss: 0.019225883901723334\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016621019906149462\n",
      "SEED: 3, FOLD: 5, EPOCH: 16, train_loss: 0.019058748727311958\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 16, valid_loss: 0.01642143389639946\n",
      "SEED: 3, FOLD: 5, EPOCH: 17, train_loss: 0.018827700207160937\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016291016784424964\n",
      "SEED: 3, FOLD: 5, EPOCH: 18, train_loss: 0.018518365592368552\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016298353385466795\n",
      "SEED: 3, FOLD: 5, EPOCH: 19, train_loss: 0.018167883308755385\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016103516691006146\n",
      "SEED: 3, FOLD: 5, EPOCH: 20, train_loss: 0.017827442532556283\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016131994171211354\n",
      "SEED: 3, FOLD: 5, EPOCH: 21, train_loss: 0.01740815003427702\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016041299041647177\n",
      "SEED: 3, FOLD: 5, EPOCH: 22, train_loss: 0.016957652868350614\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015915575723808546\n",
      "SEED: 3, FOLD: 5, EPOCH: 23, train_loss: 0.016570294942908192\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015890741219314244\n",
      "SEED: 3, FOLD: 5, EPOCH: 24, train_loss: 0.016319368223382813\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015920828383129377\n",
      "SEED: 3, FOLD: 5, EPOCH: 25, train_loss: 0.016164979746414197\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01591052645100997\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.5873648298753275\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09421128149215992\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.02967725253689128\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019758656334418517\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.021899158160227375\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018357500863763\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.020913500464647204\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01796716322692541\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.020423653938278958\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01730569523687546\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.020122167956386064\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017764678941323206\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.02000252071868729\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01722084988768284\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.019915123067393497\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01703897161552539\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.019913316830187232\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01729832560970233\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.0198884889030376\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017326183903675813\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.01986709060902531\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01708221951356301\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.019764180924441363\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016936474981216285\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.019671572372317314\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01691078681212205\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.01954844468147368\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016948195174336433\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.019521467714897683\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01694320600766402\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.01932193021717909\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016831586280694373\n",
      "SEED: 3, FOLD: 6, EPOCH: 16, train_loss: 0.0190748068176814\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016520173432162173\n",
      "SEED: 3, FOLD: 6, EPOCH: 17, train_loss: 0.018858893623424543\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016559646608164676\n",
      "SEED: 3, FOLD: 6, EPOCH: 18, train_loss: 0.018612394134539204\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016338398250249717\n",
      "SEED: 3, FOLD: 6, EPOCH: 19, train_loss: 0.01830262300633901\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01628236623051075\n",
      "SEED: 3, FOLD: 6, EPOCH: 20, train_loss: 0.017923931213649543\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016210119598186933\n",
      "SEED: 3, FOLD: 6, EPOCH: 21, train_loss: 0.017475095199974807\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016121453892153043\n",
      "SEED: 3, FOLD: 6, EPOCH: 22, train_loss: 0.017034934418326295\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 22, valid_loss: 0.01605521500683748\n",
      "SEED: 3, FOLD: 6, EPOCH: 23, train_loss: 0.01665771606604795\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 23, valid_loss: 0.01605703316342372\n",
      "SEED: 3, FOLD: 6, EPOCH: 24, train_loss: 0.01638922469086341\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016046530853670377\n",
      "SEED: 3, FOLD: 6, EPOCH: 25, train_loss: 0.016284522827009897\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016052423618160762\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.5875324243427934\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08524450143942466\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.029460028367670806\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01981194818822237\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.02181591619611592\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018796231167820785\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.021384474292800233\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017864805431320116\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.02054913913378039\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01824830028300102\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.020227742633102713\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01746194250881672\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.02003902428456255\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017386586763537847\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.020055287844828656\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017134903858487423\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.01995292031583754\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017186624069626514\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.019869671052170766\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01714559529836361\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.019835964197645318\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017045192420482635\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.019778743738660943\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017034174444583747\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.01971256300001531\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01686826147712194\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.019591612011395598\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01694036289476431\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.019442742589760472\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016841527002935227\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.019310106749872904\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01666921334197888\n",
      "SEED: 4, FOLD: 0, EPOCH: 16, train_loss: 0.019108936115092522\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016665064084988374\n",
      "SEED: 4, FOLD: 0, EPOCH: 17, train_loss: 0.018843903659364662\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016487867786334112\n",
      "SEED: 4, FOLD: 0, EPOCH: 18, train_loss: 0.01862998485464502\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016428012830706742\n",
      "SEED: 4, FOLD: 0, EPOCH: 19, train_loss: 0.018259786421785485\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016252186006078355\n",
      "SEED: 4, FOLD: 0, EPOCH: 20, train_loss: 0.017905160684037854\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016272586555435106\n",
      "SEED: 4, FOLD: 0, EPOCH: 21, train_loss: 0.01743027984441535\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016275034930843573\n",
      "SEED: 4, FOLD: 0, EPOCH: 22, train_loss: 0.017029985508604628\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 22, valid_loss: 0.0161904813721776\n",
      "SEED: 4, FOLD: 0, EPOCH: 23, train_loss: 0.016669004362680623\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016157469640557583\n",
      "SEED: 4, FOLD: 0, EPOCH: 24, train_loss: 0.016355870694324776\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016126375788679488\n",
      "SEED: 4, FOLD: 0, EPOCH: 25, train_loss: 0.01622892581429836\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01614644894233117\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.5866018141040931\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08731021674779746\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.029723820830317767\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019686814540853866\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.021990948583225946\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021144764497876167\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.021096358830864366\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018712585648665063\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.020395063971345488\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017210140107915953\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.02004791803758692\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.018773206008168366\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.02005976775812136\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017340701646529712\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.01997152036307631\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017299730545626238\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.01987874847710938\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01711593009531498\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.019894995349081786\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01708502831080785\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.019849294192484906\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01707606569219094\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.019791946343674854\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016851658574663676\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.01975064377325612\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01706115285364481\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.019590289910902847\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01682679605885194\n",
      "SEED: 4, FOLD: 1, EPOCH: 14, train_loss: 0.01945012158437355\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016750290918235596\n",
      "SEED: 4, FOLD: 1, EPOCH: 15, train_loss: 0.01935480343731674\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016572561903068654\n",
      "SEED: 4, FOLD: 1, EPOCH: 16, train_loss: 0.019149312774675922\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01656771322282461\n",
      "SEED: 4, FOLD: 1, EPOCH: 17, train_loss: 0.01892348680947278\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016487211920320988\n",
      "SEED: 4, FOLD: 1, EPOCH: 18, train_loss: 0.01859039279657441\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016239269421650812\n",
      "SEED: 4, FOLD: 1, EPOCH: 19, train_loss: 0.018285972267590666\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016207227340111367\n",
      "SEED: 4, FOLD: 1, EPOCH: 20, train_loss: 0.01794788460373073\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016184681453383885\n",
      "SEED: 4, FOLD: 1, EPOCH: 21, train_loss: 0.017448507324867957\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016036313098783676\n",
      "SEED: 4, FOLD: 1, EPOCH: 22, train_loss: 0.017071802722843917\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015963907496860393\n",
      "SEED: 4, FOLD: 1, EPOCH: 23, train_loss: 0.016665014891406975\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01597421207966713\n",
      "SEED: 4, FOLD: 1, EPOCH: 24, train_loss: 0.01642419186395568\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015947606701117296\n",
      "SEED: 4, FOLD: 1, EPOCH: 25, train_loss: 0.016254809395586316\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015920574920108684\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.5868886546105951\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.0821189874639878\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.029360496841773793\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01968049157697421\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.02184455524626616\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018077855141690143\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.02152817142573563\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017847453888792258\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.020484855096485163\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01768721081316471\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.02011657498676229\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017393812895394288\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.019979473580983845\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01711705348526056\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.020050323819993315\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0168101958787212\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.01996560794980945\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01688469358934806\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.019919944297824357\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016892738568668183\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.01985072757343988\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016927800284555324\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.01983404763647028\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01683853674106873\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.01974240126642021\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01680813951847645\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.01967057668780153\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01663024866810212\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.01958178889912528\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016508561129180286\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: 0.019339277522286046\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016539692377241757\n",
      "SEED: 4, FOLD: 2, EPOCH: 16, train_loss: 0.019096025089557107\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01639254319553192\n",
      "SEED: 4, FOLD: 2, EPOCH: 17, train_loss: 0.018935994572333387\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016283057271861114\n",
      "SEED: 4, FOLD: 2, EPOCH: 18, train_loss: 0.01863986364490277\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016023901864313163\n",
      "SEED: 4, FOLD: 2, EPOCH: 19, train_loss: 0.01830897160579224\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016073396859260704\n",
      "SEED: 4, FOLD: 2, EPOCH: 20, train_loss: 0.017963970306555967\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015909491178507987\n",
      "SEED: 4, FOLD: 2, EPOCH: 21, train_loss: 0.017507572784214408\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01587011801222196\n",
      "SEED: 4, FOLD: 2, EPOCH: 22, train_loss: 0.017120163359150693\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01580178114370658\n",
      "SEED: 4, FOLD: 2, EPOCH: 23, train_loss: 0.016748206413074118\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015762109882556476\n",
      "SEED: 4, FOLD: 2, EPOCH: 24, train_loss: 0.016475144886990655\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01575721248697776\n",
      "SEED: 4, FOLD: 2, EPOCH: 25, train_loss: 0.016366422352557246\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 25, valid_loss: 0.01577514624939515\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.5875468837046945\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08447285397694661\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.029511906559000146\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01997307687997818\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.021891596450193507\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018664861384492654\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.022610008968292055\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018472786992788315\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.020767227947913313\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01773498966716803\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.020304144913884433\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017419430928734634\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.020117090033316933\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01724138784293945\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.020090479881980934\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01726258761034562\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.019917731827779395\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01712992787361145\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.01983170722284027\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017058351865181558\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.01982704086883648\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017156342904155072\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.01971683039556484\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017011553765489504\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.019645238119001325\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01699277128164585\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.019606218799143225\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016789956376529656\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.019498554712815863\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016935171129611824\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: 0.01930204826734356\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016638727142260626\n",
      "SEED: 4, FOLD: 3, EPOCH: 16, train_loss: 0.019096496968051872\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016544340966412656\n",
      "SEED: 4, FOLD: 3, EPOCH: 17, train_loss: 0.01882474303144861\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01656281231687619\n",
      "SEED: 4, FOLD: 3, EPOCH: 18, train_loss: 0.01853116591637199\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016421027624836333\n",
      "SEED: 4, FOLD: 3, EPOCH: 19, train_loss: 0.018167739532686567\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016349581356805105\n",
      "SEED: 4, FOLD: 3, EPOCH: 20, train_loss: 0.017767974326538073\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016313215144551717\n",
      "SEED: 4, FOLD: 3, EPOCH: 21, train_loss: 0.017327003231322444\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 21, valid_loss: 0.0161933798629504\n",
      "SEED: 4, FOLD: 3, EPOCH: 22, train_loss: 0.01680675458565757\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016187176681481875\n",
      "SEED: 4, FOLD: 3, EPOCH: 23, train_loss: 0.016363042922740854\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01613976491185335\n",
      "SEED: 4, FOLD: 3, EPOCH: 24, train_loss: 0.016013334996092157\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016104265904197328\n",
      "SEED: 4, FOLD: 3, EPOCH: 25, train_loss: 0.015922050570716727\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016097016632556915\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.5890289823952559\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.09863868011878087\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.029681621849335527\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.021705789491534233\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.02231335307697992\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01822020708081814\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.021041870394067186\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017359659648858584\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.020422973720407165\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01716220944833297\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.020206688500538066\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01713929748019347\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.02001448635112595\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01691594863167176\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.02005127882836638\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016966206809649102\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.020042149551414156\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016840268714496724\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.019933241822228238\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01677165595957866\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.019881015140059834\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016605305270506784\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.019853631739278097\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016803407683395423\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.01977289722275895\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016610387712717056\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.019717292079853045\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01646553796644394\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.01947563957120921\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016692141214242347\n",
      "SEED: 4, FOLD: 4, EPOCH: 15, train_loss: 0.01937564308880954\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016419481342801683\n",
      "SEED: 4, FOLD: 4, EPOCH: 16, train_loss: 0.019144292845315224\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016319958851314507\n",
      "SEED: 4, FOLD: 4, EPOCH: 17, train_loss: 0.018974725660440082\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016160691228623573\n",
      "SEED: 4, FOLD: 4, EPOCH: 18, train_loss: 0.018675997224007104\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01610758800346118\n",
      "SEED: 4, FOLD: 4, EPOCH: 19, train_loss: 0.018343182708564644\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01590901928452345\n",
      "SEED: 4, FOLD: 4, EPOCH: 20, train_loss: 0.01790945209260728\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015840661711990833\n",
      "SEED: 4, FOLD: 4, EPOCH: 21, train_loss: 0.017549085531484435\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015680925060923282\n",
      "SEED: 4, FOLD: 4, EPOCH: 22, train_loss: 0.01716434379183763\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015683351800991938\n",
      "SEED: 4, FOLD: 4, EPOCH: 23, train_loss: 0.016747094124454905\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015669134732049245\n",
      "SEED: 4, FOLD: 4, EPOCH: 24, train_loss: 0.01651347163007469\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015622759882647257\n",
      "SEED: 4, FOLD: 4, EPOCH: 25, train_loss: 0.016362360515002464\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 25, valid_loss: 0.015634359433673896\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.5867470570311353\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08404539238948089\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.02981904546755391\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.02003847248852253\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.021996018678151274\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018910295115067408\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.02112779169771317\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01806735949447522\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.020367827190942055\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.0173491954516906\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.020070564303849195\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017102436950573556\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.02002107533248695\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.01692441635980056\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.0199111739072848\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017051220799867924\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.019827698986675288\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.01709367248874444\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.01984547745637797\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.017103647669920556\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.019861358620629117\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01728712796018674\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.019745428996110283\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.01662923166385064\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.019632159178522793\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.01681158462396035\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.019508501766501245\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016911313224297304\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.01944793846357513\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016792762738007765\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.019302263453200057\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016562127579863254\n",
      "SEED: 4, FOLD: 5, EPOCH: 16, train_loss: 0.019028340491491394\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016540437793502442\n",
      "SEED: 4, FOLD: 5, EPOCH: 17, train_loss: 0.01878750226082834\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016327284276485443\n",
      "SEED: 4, FOLD: 5, EPOCH: 18, train_loss: 0.018494985217379557\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016317967468729384\n",
      "SEED: 4, FOLD: 5, EPOCH: 19, train_loss: 0.018165026023681904\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016197099780234005\n",
      "SEED: 4, FOLD: 5, EPOCH: 20, train_loss: 0.017820458683009084\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 20, valid_loss: 0.01626866303670865\n",
      "SEED: 4, FOLD: 5, EPOCH: 21, train_loss: 0.01740182296851197\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01607333911726108\n",
      "SEED: 4, FOLD: 5, EPOCH: 22, train_loss: 0.016928214126744785\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 22, valid_loss: 0.016068836530813806\n",
      "SEED: 4, FOLD: 5, EPOCH: 23, train_loss: 0.016537388056718016\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 23, valid_loss: 0.016036350423326858\n",
      "SEED: 4, FOLD: 5, EPOCH: 24, train_loss: 0.01625208549100805\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 24, valid_loss: 0.016038822798201673\n",
      "SEED: 4, FOLD: 5, EPOCH: 25, train_loss: 0.016122927675275383\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 25, valid_loss: 0.016037877863989428\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.5864337491425308\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09116575866937637\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.02945063686048662\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020482629680862792\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.021813283523393644\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018395889837008256\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.02095815131591784\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01779267306511219\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.020277669099537102\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017399031812181838\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.02004601537073786\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01818521421116132\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.02002225088811404\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017332272317547064\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.019928272310140972\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017481860776360218\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.019899420314342588\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01739570627418848\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.0197907220823942\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017101800212493308\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.01981053883964951\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017319926275656775\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.01981176695207486\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017294987892875306\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.019729780310110467\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.017089269338892057\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.01965137228772447\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01701916388880748\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.019465702862755674\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01695982925593853\n",
      "SEED: 4, FOLD: 6, EPOCH: 15, train_loss: 0.019254094090413402\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016780265248738803\n",
      "SEED: 4, FOLD: 6, EPOCH: 16, train_loss: 0.019044949295553\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016663867263839796\n",
      "SEED: 4, FOLD: 6, EPOCH: 17, train_loss: 0.018934010024610405\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016599940852477\n",
      "SEED: 4, FOLD: 6, EPOCH: 18, train_loss: 0.018608296290040016\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01656990233235634\n",
      "SEED: 4, FOLD: 6, EPOCH: 19, train_loss: 0.018290781315315415\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016399448737502098\n",
      "SEED: 4, FOLD: 6, EPOCH: 20, train_loss: 0.017936683989859915\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01630779255468112\n",
      "SEED: 4, FOLD: 6, EPOCH: 21, train_loss: 0.017521508063214855\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01624146454895918\n",
      "SEED: 4, FOLD: 6, EPOCH: 22, train_loss: 0.01713126164080726\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 22, valid_loss: 0.01623986905010847\n",
      "SEED: 4, FOLD: 6, EPOCH: 23, train_loss: 0.016781974923671096\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016213195971571483\n",
      "SEED: 4, FOLD: 6, EPOCH: 24, train_loss: 0.01649328157607768\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01621856805510246\n",
      "SEED: 4, FOLD: 6, EPOCH: 25, train_loss: 0.01637125131044839\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016225464928608675\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.5894818119704723\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.09181597026494834\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.029457610176020377\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02001648281629269\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.021766153088695294\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01937621975174317\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.020939396618789918\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018574772832485344\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.020367037026664696\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017718545232827846\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.020093387445888004\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017458729445934296\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.02000237656505527\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017475178465247154\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.019976105138256744\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01779098665485015\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.02001336116243053\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017340886478240673\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.019864562747849\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.0172142694489314\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.019866154579496063\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017243210799418963\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.019775680744567432\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017166648203363784\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.019699871766607504\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017216003141724147\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.01958818663213704\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01693813832333455\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.019470992472928925\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.017064554473528497\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: 0.01935444080044289\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016875463896072827\n",
      "SEED: 5, FOLD: 0, EPOCH: 16, train_loss: 0.01916534556831057\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016717329119833615\n",
      "SEED: 5, FOLD: 0, EPOCH: 17, train_loss: 0.018895591332300288\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01653966923745779\n",
      "SEED: 5, FOLD: 0, EPOCH: 18, train_loss: 0.01860705581871239\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016423439965225183\n",
      "SEED: 5, FOLD: 0, EPOCH: 19, train_loss: 0.01831209714952353\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016267299580459412\n",
      "SEED: 5, FOLD: 0, EPOCH: 20, train_loss: 0.017904733156634343\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016338183616216365\n",
      "SEED: 5, FOLD: 0, EPOCH: 21, train_loss: 0.017527433363972483\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016211484702160724\n",
      "SEED: 5, FOLD: 0, EPOCH: 22, train_loss: 0.017104902342465277\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01612490823922249\n",
      "SEED: 5, FOLD: 0, EPOCH: 23, train_loss: 0.016729646513389575\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016094459937169\n",
      "SEED: 5, FOLD: 0, EPOCH: 24, train_loss: 0.016496261065775477\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01610045378597883\n",
      "SEED: 5, FOLD: 0, EPOCH: 25, train_loss: 0.01634006871766335\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016090742455652125\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.5876053202192526\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08296191921600929\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.02986752083273353\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020134252281143114\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.022058938831292296\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01825816513827214\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.02117842632169659\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.028684651479125023\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.020833984923523827\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01730552953309738\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.020241400780710014\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.018116635986818716\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.02017770050647291\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01703863340215041\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.020054299485039066\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01690094223102698\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.020022583873690786\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01692737001352585\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.019887535379746475\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017004155124036167\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.019896387625989075\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01674554246262862\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.019812427914223156\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01693621206168945\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.019750359266795015\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016613909115011875\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.01960605355231343\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01660770084708929\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.01953044271952397\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016566570490025558\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.019418591683780826\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016346921642812397\n",
      "SEED: 5, FOLD: 1, EPOCH: 16, train_loss: 0.019165564479457366\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016417761261646565\n",
      "SEED: 5, FOLD: 1, EPOCH: 17, train_loss: 0.018938051133945182\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016182007984473154\n",
      "SEED: 5, FOLD: 1, EPOCH: 18, train_loss: 0.018654853533450012\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016076508837823685\n",
      "SEED: 5, FOLD: 1, EPOCH: 19, train_loss: 0.018366013225671406\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016095277996590503\n",
      "SEED: 5, FOLD: 1, EPOCH: 20, train_loss: 0.01800630707293749\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01581315338038481\n",
      "SEED: 5, FOLD: 1, EPOCH: 21, train_loss: 0.017563466385409638\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015950315345365267\n",
      "SEED: 5, FOLD: 1, EPOCH: 22, train_loss: 0.017183830445581996\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015817047741550665\n",
      "SEED: 5, FOLD: 1, EPOCH: 23, train_loss: 0.016805582390343014\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015775600734811563\n",
      "SEED: 5, FOLD: 1, EPOCH: 24, train_loss: 0.01653912659684146\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015774535445066597\n",
      "SEED: 5, FOLD: 1, EPOCH: 25, train_loss: 0.016421395643438037\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015774087550548408\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.5889453834577186\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08794381870673253\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.029798369703663362\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02031498631605735\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.021936804886806657\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.023228006867262032\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.02121063374687691\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017561771548711337\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.02055138852950689\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017500286348737203\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.02022030113919361\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01764314191845747\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.020110528840607888\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01787546663903273\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.020030007848667132\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01711374893784523\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.01992503699620028\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017023897586533658\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.01997127565177711\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01718136524924865\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.019870597919499553\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01704749808861659\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.01983874336489149\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016555660977386512\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.01973865206378537\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.0167668299892774\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.019683838217846444\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016595566143783238\n",
      "SEED: 5, FOLD: 2, EPOCH: 14, train_loss: 0.019514952282849198\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01661444562845505\n",
      "SEED: 5, FOLD: 2, EPOCH: 15, train_loss: 0.01935288994698911\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01662414872015898\n",
      "SEED: 5, FOLD: 2, EPOCH: 16, train_loss: 0.01919596632187431\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016517431618502505\n",
      "SEED: 5, FOLD: 2, EPOCH: 17, train_loss: 0.01897249562112061\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016411744702893954\n",
      "SEED: 5, FOLD: 2, EPOCH: 18, train_loss: 0.018673918512020563\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016337658207003888\n",
      "SEED: 5, FOLD: 2, EPOCH: 19, train_loss: 0.018359386840382137\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016155731076231368\n",
      "SEED: 5, FOLD: 2, EPOCH: 20, train_loss: 0.017913795957291447\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 20, valid_loss: 0.0160536842707258\n",
      "SEED: 5, FOLD: 2, EPOCH: 21, train_loss: 0.017497349832509015\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016014075336547997\n",
      "SEED: 5, FOLD: 2, EPOCH: 22, train_loss: 0.017097728842919744\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01601388341245743\n",
      "SEED: 5, FOLD: 2, EPOCH: 23, train_loss: 0.016726281934392614\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015994710131333426\n",
      "SEED: 5, FOLD: 2, EPOCH: 24, train_loss: 0.016437385860528494\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016000484617856834\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.5866988068698226\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08149476635914582\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.02965158611737393\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019997468074926965\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.022062100319040788\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018628759452929862\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.0214366910073\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017587194863993388\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.02040887639127873\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017353049765985746\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.02013944975427679\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017865144146176484\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.02007051250217734\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017012424050615385\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.020009224529604654\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01701768716940513\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.01990245353128459\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.0168829200646052\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.01988914402554164\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016850994255107183\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.019862981865534913\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017037390946195677\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.019822002589903975\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01676488209229249\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.01976274696455614\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01673319534613536\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.01965180114918464\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016686288711543266\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.01950490170133275\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016628405795647547\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: 0.019345005546268577\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01646051799448637\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: 0.01917043366041538\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016428221088762466\n",
      "SEED: 5, FOLD: 3, EPOCH: 17, train_loss: 0.018913138834004466\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01638849566762264\n",
      "SEED: 5, FOLD: 3, EPOCH: 18, train_loss: 0.018671915916776336\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016186451252836447\n",
      "SEED: 5, FOLD: 3, EPOCH: 19, train_loss: 0.018396389721011795\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016095115731541928\n",
      "SEED: 5, FOLD: 3, EPOCH: 20, train_loss: 0.01796294824295753\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01608830812172248\n",
      "SEED: 5, FOLD: 3, EPOCH: 21, train_loss: 0.017583247991530476\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01597535961235945\n",
      "SEED: 5, FOLD: 3, EPOCH: 22, train_loss: 0.017143584750089293\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015981026710225985\n",
      "SEED: 5, FOLD: 3, EPOCH: 23, train_loss: 0.016776715103234793\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015949755907058716\n",
      "SEED: 5, FOLD: 3, EPOCH: 24, train_loss: 0.016494534104257018\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015942333122858636\n",
      "SEED: 5, FOLD: 3, EPOCH: 25, train_loss: 0.01637011719867587\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 25, valid_loss: 0.015957164434859387\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.5873977473458728\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08669459877105859\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.029955930428931844\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019974016799376562\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.02180382048056738\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01826107487655603\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.021023028781889257\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017663331272510383\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.020379663998814853\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.03317290716446363\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.020210174717814534\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017217007107459582\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.020066783914493548\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01709230229831659\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.019971925941472117\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017087051071799718\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.019869749912539043\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01730286430280942\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.019914172715633303\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017004394617218237\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.019912453594844084\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017308782069728926\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.019832393708261283\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01704880824455848\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.019711762993923715\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01706014645214264\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.01961522879129326\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01693331736784715\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.01950485249226158\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016812995076179504\n",
      "SEED: 5, FOLD: 4, EPOCH: 15, train_loss: 0.019361984588809916\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016697855093158208\n",
      "SEED: 5, FOLD: 4, EPOCH: 16, train_loss: 0.019104445176954206\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016657304448577073\n",
      "SEED: 5, FOLD: 4, EPOCH: 17, train_loss: 0.018964068787927564\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016528422156205543\n",
      "SEED: 5, FOLD: 4, EPOCH: 18, train_loss: 0.018644891880654\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016452698323589105\n",
      "SEED: 5, FOLD: 4, EPOCH: 19, train_loss: 0.018374724489812914\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01629474529853234\n",
      "SEED: 5, FOLD: 4, EPOCH: 20, train_loss: 0.017952444434568688\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01617766787799505\n",
      "SEED: 5, FOLD: 4, EPOCH: 21, train_loss: 0.01756434318785732\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016127106733620167\n",
      "SEED: 5, FOLD: 4, EPOCH: 22, train_loss: 0.017116304575088056\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016081593142679103\n",
      "SEED: 5, FOLD: 4, EPOCH: 23, train_loss: 0.01683293012398723\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016041616837565716\n",
      "SEED: 5, FOLD: 4, EPOCH: 24, train_loss: 0.016477087701393944\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01601568623804129\n",
      "SEED: 5, FOLD: 4, EPOCH: 25, train_loss: 0.01640651748842887\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016003247851935718\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.5882548811669285\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.0808866024017334\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.029933988922149747\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.019902384768311795\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.02186174293023509\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.0181819753578076\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.021409675856498448\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01776515835752854\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.02053683905585392\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017507810432177324\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.02098264132399817\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017493519502190445\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.02031242200551001\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017108724524195377\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.02016699022135219\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017364901777070302\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.02000831998884678\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.01716306934563013\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.019971671967288933\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.0171381772424166\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.020021688394449854\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016807597846939012\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.01989606463325185\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.01680434301782113\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.01983012420100135\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016876729420171335\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.01967942953814526\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.017018175755555812\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.019618057192781486\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016706946019369822\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.019380900782306452\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016579300021895997\n",
      "SEED: 5, FOLD: 5, EPOCH: 16, train_loss: 0.019263378243792702\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 16, valid_loss: 0.01655529998242855\n",
      "SEED: 5, FOLD: 5, EPOCH: 17, train_loss: 0.01899748222550025\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016463454096363142\n",
      "SEED: 5, FOLD: 5, EPOCH: 18, train_loss: 0.018696509956105334\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016255496069788933\n",
      "SEED: 5, FOLD: 5, EPOCH: 19, train_loss: 0.018423734232783318\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016180220776452467\n",
      "SEED: 5, FOLD: 5, EPOCH: 20, train_loss: 0.018063724468890076\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 20, valid_loss: 0.01613115770025895\n",
      "SEED: 5, FOLD: 5, EPOCH: 21, train_loss: 0.0176441673743161\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01602747692511632\n",
      "SEED: 5, FOLD: 5, EPOCH: 22, train_loss: 0.017222927241409954\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015914141128842648\n",
      "SEED: 5, FOLD: 5, EPOCH: 23, train_loss: 0.016870260905675793\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01596541337382335\n",
      "SEED: 5, FOLD: 5, EPOCH: 24, train_loss: 0.016636611503624433\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015928615601016924\n",
      "SEED: 5, FOLD: 5, EPOCH: 25, train_loss: 0.01647759471843774\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015934219368948385\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.587026850697962\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09399058268620418\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.029640090475614007\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020147203252865717\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.021772986680671975\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.02064589482660477\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.021067382692283875\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017897741869091988\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.02038158493972308\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01745696050616411\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.020012228372129234\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017545520542905882\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.0200591686408262\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01732593015409433\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.01998492972170179\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01732149698699896\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.019977801731108007\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017301584164110515\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.019955942961009773\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017184029763134625\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.019874318804893945\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017174392365492307\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.019825281172588066\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016929812299517486\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.019649757248525683\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016789633350876663\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.019599298745192385\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.017018138001171444\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.01956161781138665\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016754847449752\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: 0.019288115304064105\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016751524562445972\n",
      "SEED: 5, FOLD: 6, EPOCH: 16, train_loss: 0.01913147870249845\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01654170245791857\n",
      "SEED: 5, FOLD: 6, EPOCH: 17, train_loss: 0.018915581743459444\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01635368591031203\n",
      "SEED: 5, FOLD: 6, EPOCH: 18, train_loss: 0.01861806445427843\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016386938138076894\n",
      "SEED: 5, FOLD: 6, EPOCH: 19, train_loss: 0.018273507093859685\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01629497820081619\n",
      "SEED: 5, FOLD: 6, EPOCH: 20, train_loss: 0.017895733862108475\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016176055901898787\n",
      "SEED: 5, FOLD: 6, EPOCH: 21, train_loss: 0.017462978642937298\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01615029301207799\n",
      "SEED: 5, FOLD: 6, EPOCH: 22, train_loss: 0.017069026399907226\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016066978685557842\n",
      "SEED: 5, FOLD: 6, EPOCH: 23, train_loss: 0.016649065652509797\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016048676119400904\n",
      "SEED: 5, FOLD: 6, EPOCH: 24, train_loss: 0.016381749770025145\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01606639238217702\n",
      "SEED: 5, FOLD: 6, EPOCH: 25, train_loss: 0.01625213409597809\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 25, valid_loss: 0.01605147674966317\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.5875688995662574\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08693405985832214\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.0293640618439059\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020079032876170598\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.021995902464196488\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019121710067758195\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.021101356458825035\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017484613192769196\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.022377744166029466\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017518020879763823\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.02048457761269969\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017400249408987854\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.020161884585143747\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017186758036796864\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.02010688965989126\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.0168644583855684\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.02000447438174003\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017119223825060405\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.019951425140371192\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016769789087657746\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.019895736933559983\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01703625050588296\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.01982767864860393\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01675168417680722\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.019777472735055396\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01672618850492514\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.019618296139949077\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016365349006194334\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.019497651027867925\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016332864689712342\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.01933577686950967\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01619603133832033\n",
      "SEED: 6, FOLD: 0, EPOCH: 16, train_loss: 0.019127929885242437\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01637272980923836\n",
      "SEED: 6, FOLD: 0, EPOCH: 17, train_loss: 0.018973900609322497\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016121190112943832\n",
      "SEED: 6, FOLD: 0, EPOCH: 18, train_loss: 0.018600040971225983\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01604510421076646\n",
      "SEED: 6, FOLD: 0, EPOCH: 19, train_loss: 0.01829688887841798\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015929345399714433\n",
      "SEED: 6, FOLD: 0, EPOCH: 20, train_loss: 0.01788790277331262\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015892398400375478\n",
      "SEED: 6, FOLD: 0, EPOCH: 21, train_loss: 0.017413662394156326\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015849308254053958\n",
      "SEED: 6, FOLD: 0, EPOCH: 22, train_loss: 0.0169338786823524\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01582730246277956\n",
      "SEED: 6, FOLD: 0, EPOCH: 23, train_loss: 0.016534423745061096\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01581877047339311\n",
      "SEED: 6, FOLD: 0, EPOCH: 24, train_loss: 0.016204697784741182\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 24, valid_loss: 0.0158615827990266\n",
      "SEED: 6, FOLD: 0, EPOCH: 25, train_loss: 0.016062032846683585\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01582076522306754\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.5876007799965304\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08684617109023608\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.02954571835092596\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019748333411721084\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.021851935197372694\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018458958715200424\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.021262274853683805\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01766696858864564\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.020491833496536757\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01777712986446344\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.02018918321040031\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01746507390187337\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.020140060273980773\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017281435286769502\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.02011846365860185\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017120034648821905\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.019911654167682737\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01713230088353157\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.019942376234040066\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017069613561034203\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.019903382815017894\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01700363064614626\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.01984029371492766\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016921982885553286\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.01976479365918282\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016778871990167178\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.019676202329228055\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016855429857969284\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.01951757790772496\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016599766050393764\n",
      "SEED: 6, FOLD: 1, EPOCH: 15, train_loss: 0.019323339308234485\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01652174385694357\n",
      "SEED: 6, FOLD: 1, EPOCH: 16, train_loss: 0.019109804132902943\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016506729217676017\n",
      "SEED: 6, FOLD: 1, EPOCH: 17, train_loss: 0.018874148787880265\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016522881718209155\n",
      "SEED: 6, FOLD: 1, EPOCH: 18, train_loss: 0.018630812422850647\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016258349140676167\n",
      "SEED: 6, FOLD: 1, EPOCH: 19, train_loss: 0.01829452072647778\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01612793145558009\n",
      "SEED: 6, FOLD: 1, EPOCH: 20, train_loss: 0.01790589904664336\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016122091561555862\n",
      "SEED: 6, FOLD: 1, EPOCH: 21, train_loss: 0.017515877941371622\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016088625989281215\n",
      "SEED: 6, FOLD: 1, EPOCH: 22, train_loss: 0.017075846789757144\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016058102823220767\n",
      "SEED: 6, FOLD: 1, EPOCH: 23, train_loss: 0.016663612936296174\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016053827909322884\n",
      "SEED: 6, FOLD: 1, EPOCH: 24, train_loss: 0.016424612167316513\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016021026226763543\n",
      "SEED: 6, FOLD: 1, EPOCH: 25, train_loss: 0.016216898185981286\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 25, valid_loss: 0.016059653976788886\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.5885336268189791\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08552438536515602\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.02966263167862151\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019838969724682663\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.02176402647652336\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018132371541399222\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.0209375602772107\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018114168483477373\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.020682521164417267\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017846648652966205\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.0202082110367514\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017442957713053778\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.020093656195377983\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017245497124699447\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.0199907623432778\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01718138401898054\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.01997955855787606\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01706298512335007\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.019987640247957128\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01700097809617336\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.019949909475808207\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016900889575481415\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.01985516200295171\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016837529838085175\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.019730047272467934\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016687986440956593\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.019603706090836913\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016898373858286783\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.019550440002333472\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01684843161358283\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.01939831384633844\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016663858380455237\n",
      "SEED: 6, FOLD: 2, EPOCH: 16, train_loss: 0.019223311035012878\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01655917285153499\n",
      "SEED: 6, FOLD: 2, EPOCH: 17, train_loss: 0.018933233930855185\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01650848024739669\n",
      "SEED: 6, FOLD: 2, EPOCH: 18, train_loss: 0.018640381258887215\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016453122935042933\n",
      "SEED: 6, FOLD: 2, EPOCH: 19, train_loss: 0.01841760308456582\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016139982268214226\n",
      "SEED: 6, FOLD: 2, EPOCH: 20, train_loss: 0.018033927809950466\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016135182589865647\n",
      "SEED: 6, FOLD: 2, EPOCH: 21, train_loss: 0.017587940359639155\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015990824152070742\n",
      "SEED: 6, FOLD: 2, EPOCH: 22, train_loss: 0.017189382512525126\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015977758412750866\n",
      "SEED: 6, FOLD: 2, EPOCH: 23, train_loss: 0.016824477641667064\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015917840485389415\n",
      "SEED: 6, FOLD: 2, EPOCH: 24, train_loss: 0.01658508395524444\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015943347977904174\n",
      "SEED: 6, FOLD: 2, EPOCH: 25, train_loss: 0.016477869508939015\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015935390542906065\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.5886776208676197\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08691418400177589\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.029776604644752836\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019990183269748323\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.021909510867821204\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018489743367983744\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.021026317533609028\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017585262942772645\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.02046270839668609\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017213518659655865\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.020161993474372336\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017181477294518396\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.020073948503547424\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017051919005238093\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.019997829697220713\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017173262886129893\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.01993975607124535\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017233942420436785\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.01996347982738469\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016929333456433736\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.019830208674475953\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016980653198865745\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.019787187914590578\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017074227189788453\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.01971168050894866\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016736931454103727\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.019608019977002532\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01665959399766647\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.019485636438066896\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016702409117267683\n",
      "SEED: 6, FOLD: 3, EPOCH: 15, train_loss: 0.019357966963906546\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016653091575090703\n",
      "SEED: 6, FOLD: 3, EPOCH: 16, train_loss: 0.019182926043868065\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016480666441986196\n",
      "SEED: 6, FOLD: 3, EPOCH: 17, train_loss: 0.01900749439625321\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016315375454723835\n",
      "SEED: 6, FOLD: 3, EPOCH: 18, train_loss: 0.018684770333001744\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016218154977720518\n",
      "SEED: 6, FOLD: 3, EPOCH: 19, train_loss: 0.018340831974873673\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016169244351868447\n",
      "SEED: 6, FOLD: 3, EPOCH: 20, train_loss: 0.01789542448681754\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016117488535550926\n",
      "SEED: 6, FOLD: 3, EPOCH: 21, train_loss: 0.017536949693552545\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016167645271007832\n",
      "SEED: 6, FOLD: 3, EPOCH: 22, train_loss: 0.01712650419338732\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01603002674304522\n",
      "SEED: 6, FOLD: 3, EPOCH: 23, train_loss: 0.016748622915632016\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015975548026080314\n",
      "SEED: 6, FOLD: 3, EPOCH: 24, train_loss: 0.016508269841103134\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01598154423901668\n",
      "SEED: 6, FOLD: 3, EPOCH: 25, train_loss: 0.016372240740000397\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 25, valid_loss: 0.01597282412247016\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.5897872247607321\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08571623323055413\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.029615216510924133\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020111914437550765\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.022035659618071607\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018276684559308566\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.021394635424823373\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017907926812767982\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.02043372010057037\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017403566636718236\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.02013801959519451\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017611554752175625\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.020097345113754272\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.018914193631364748\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.020225866798412154\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017124366874878224\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.019936104607139085\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017092713799614172\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.019919460639357567\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017378064445578136\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.01985609264591256\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017151100274461966\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.019740609955546017\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01694132058093181\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.019681181154541066\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01694584308335414\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.019630148704793002\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01689268505344024\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.01946010672160097\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01674781460314989\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.019259598332683783\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01683089889299411\n",
      "SEED: 6, FOLD: 4, EPOCH: 16, train_loss: 0.019110719849531714\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01671156666886348\n",
      "SEED: 6, FOLD: 4, EPOCH: 17, train_loss: 0.018834771940837037\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016529909120156214\n",
      "SEED: 6, FOLD: 4, EPOCH: 18, train_loss: 0.018675426398781506\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016463844678722896\n",
      "SEED: 6, FOLD: 4, EPOCH: 19, train_loss: 0.018360913328423694\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016255632114525024\n",
      "SEED: 6, FOLD: 4, EPOCH: 20, train_loss: 0.017962465163420985\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016240903749488868\n",
      "SEED: 6, FOLD: 4, EPOCH: 21, train_loss: 0.01755439885262702\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016210755978066187\n",
      "SEED: 6, FOLD: 4, EPOCH: 22, train_loss: 0.017177690575654443\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016086150247317094\n",
      "SEED: 6, FOLD: 4, EPOCH: 23, train_loss: 0.016834158261583465\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016048149707225654\n",
      "SEED: 6, FOLD: 4, EPOCH: 24, train_loss: 0.016599977993079135\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016019639917291127\n",
      "SEED: 6, FOLD: 4, EPOCH: 25, train_loss: 0.01645869146277373\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01604602521715256\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.587237033086854\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08796176887475528\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.029304451913245627\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.019768662894001372\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.021795443309521354\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.0181563116180209\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.020843520382972987\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017833414415900525\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.020284012790668656\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.01721505383745982\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.020070827566087246\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.01725923943404968\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.019995783078106674\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017174068838357925\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.01993710107195216\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.016902829233843546\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.0198784871782\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017204331090817086\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.019871804284284245\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016871835893163316\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.019794190629712632\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016959806331075154\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.019767714538485616\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016781216415648278\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.019674738139115477\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016953000583900854\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.019563646332637685\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01698445636205948\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.01945557037519442\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016692252829670906\n",
      "SEED: 6, FOLD: 5, EPOCH: 15, train_loss: 0.019247993424132064\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016534852150541086\n",
      "SEED: 6, FOLD: 5, EPOCH: 16, train_loss: 0.019007885677588952\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016474557324097708\n",
      "SEED: 6, FOLD: 5, EPOCH: 17, train_loss: 0.01886865947194196\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016342241460314162\n",
      "SEED: 6, FOLD: 5, EPOCH: 18, train_loss: 0.018580351654138114\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016284033441199705\n",
      "SEED: 6, FOLD: 5, EPOCH: 19, train_loss: 0.018174888742332522\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016245511145545885\n",
      "SEED: 6, FOLD: 5, EPOCH: 20, train_loss: 0.017835363166759145\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016095507961626235\n",
      "SEED: 6, FOLD: 5, EPOCH: 21, train_loss: 0.017414444000334352\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01602423169578497\n",
      "SEED: 6, FOLD: 5, EPOCH: 22, train_loss: 0.017006222334866587\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 22, valid_loss: 0.016004258551849768\n",
      "SEED: 6, FOLD: 5, EPOCH: 23, train_loss: 0.01661529519116959\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01602457255984728\n",
      "SEED: 6, FOLD: 5, EPOCH: 24, train_loss: 0.016407625095264333\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015988667495548725\n",
      "SEED: 6, FOLD: 5, EPOCH: 25, train_loss: 0.016277920605765807\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015984511790940396\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.5873343328366408\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08574983649528943\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.029668442200164537\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019887009635567665\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.021863421072831023\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01823101765834368\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.020984513911645155\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01779282823778116\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.02061569652948025\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0174530608436236\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.020224381263393\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017496041523722503\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.019997900427394622\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01719601609959052\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.0199383027549531\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017081582488921974\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.01986444811965968\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01699816041554396\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.019936558337429085\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017140996140929367\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.019810743529248883\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01716908053136789\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.019821104316695315\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016845695674419403\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.019693772837116912\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.017097138584806368\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.019511854099864896\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016800831000392254\n",
      "SEED: 6, FOLD: 6, EPOCH: 14, train_loss: 0.019522844134150324\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016776011397059146\n",
      "SEED: 6, FOLD: 6, EPOCH: 15, train_loss: 0.019308001558120187\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016793013335420534\n",
      "SEED: 6, FOLD: 6, EPOCH: 16, train_loss: 0.019056390694065672\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01644543966708275\n",
      "SEED: 6, FOLD: 6, EPOCH: 17, train_loss: 0.018849961157586123\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01649741126367679\n",
      "SEED: 6, FOLD: 6, EPOCH: 18, train_loss: 0.018584691214601736\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01637920644134283\n",
      "SEED: 6, FOLD: 6, EPOCH: 19, train_loss: 0.01825412453429119\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016222412411410075\n",
      "SEED: 6, FOLD: 6, EPOCH: 20, train_loss: 0.01787974451341339\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016177097192177407\n",
      "SEED: 6, FOLD: 6, EPOCH: 21, train_loss: 0.017504463022625125\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016115728120964307\n",
      "SEED: 6, FOLD: 6, EPOCH: 22, train_loss: 0.0170652267296572\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016083950678316448\n",
      "SEED: 6, FOLD: 6, EPOCH: 23, train_loss: 0.016731658220492506\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 23, valid_loss: 0.01603978069928976\n",
      "SEED: 6, FOLD: 6, EPOCH: 24, train_loss: 0.016432781980649847\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01603188465994138\n",
      "SEED: 6, FOLD: 6, EPOCH: 25, train_loss: 0.01629019888570985\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016048260534612033\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T09:41:18.530412Z",
     "iopub.status.busy": "2020-11-29T09:41:18.529334Z",
     "iopub.status.idle": "2020-11-29T09:41:21.396554Z",
     "shell.execute_reply": "2020-11-29T09:41:21.395453Z"
    },
    "papermill": {
     "duration": 3.789438,
     "end_time": "2020-11-29T09:41:21.396687",
     "exception": false,
     "start_time": "2020-11-29T09:41:17.607249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014536705926290352\n",
      "Overall AUC:  0.824964832872721\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "cv_score = 0\n",
    "roc_score = 0\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    cv_score += log_loss(y_true[:, i], y_pred[:, i])\n",
    "    roc_score +=roc_auc_score(y_true[:, i], y_pred[:, i], average='micro')\n",
    "\n",
    "print(\"CV log_loss: \", cv_score / y_pred.shape[1])\n",
    "print(\"Overall AUC: \", roc_score / y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T09:41:23.229714Z",
     "iopub.status.busy": "2020-11-29T09:41:23.228654Z",
     "iopub.status.idle": "2020-11-29T09:41:36.924740Z",
     "shell.execute_reply": "2020-11-29T09:41:36.923378Z"
    },
    "papermill": {
     "duration": 14.626161,
     "end_time": "2020-11-29T09:41:36.924898",
     "exception": false,
     "start_time": "2020-11-29T09:41:22.298737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_pretrain= valid_results[target_cols]\n",
    "oof_pretrain.to_csv('off_pretrain_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T09:41:39.134186Z",
     "iopub.status.busy": "2020-11-29T09:41:39.131126Z",
     "iopub.status.idle": "2020-11-29T09:41:40.932615Z",
     "shell.execute_reply": "2020-11-29T09:41:40.931271Z"
    },
    "papermill": {
     "duration": 3.104665,
     "end_time": "2020-11-29T09:41:40.932753",
     "exception": false,
     "start_time": "2020-11-29T09:41:37.828088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_id = list(df['sig_id'].values)\n",
    "test_id = list(test_features['sig_id'].values)\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=target_cols)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_submit.loc[test.sig_id,:] = test[target_cols].values\n",
    "df_submit.loc[test_features[test_features.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.903732,
     "end_time": "2020-11-29T09:41:42.747277",
     "exception": false,
     "start_time": "2020-11-29T09:41:41.843545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your support motivates me to share kernels like these ... so please \" Do UPVOTE \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.901479,
     "end_time": "2020-11-29T09:41:44.552037",
     "exception": false,
     "start_time": "2020-11-29T09:41:43.650558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4464.164977,
   "end_time": "2020-11-29T09:41:45.962391",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-29T08:27:21.797414",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
